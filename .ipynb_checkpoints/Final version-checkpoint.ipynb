{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "from utils import preprocessing_utils, general_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets: train, test, store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_PATH + 'train.csv', low_memory=False)\n",
    "test_df = pd.read_csv(DATA_PATH + 'test.csv', low_memory=False)\n",
    "store_df = pd.read_csv(DATA_PATH + 'store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date'] = pd.to_datetime(train_df['Date'], infer_datetime_format=True)\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01 00:00:00 2015-07-31 00:00:00\n",
      "2015-08-01 00:00:00 2015-09-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Date'].min(), train_df['Date'].max())\n",
    "print(test_df['Date'].min(), test_df['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sample = np.random.choice(100, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Store'].isin(store_sample)].reset_index(drop=True)\n",
    "test_df = test_df[test_df['Store'].isin(store_sample)].reset_index(drop=True)\n",
    "store_df = store_df[store_df['Store'].isin(store_sample)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data 2013, 2014 and 2015 till 2015-07-31. \\\n",
    "We need to predict sales for the next 1,5 month i.e. 47 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Open'] = test_df.groupby('Store')['Open'].ffill()\n",
    "test_df['Open'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "Store            0\n",
       "DayOfWeek        0\n",
       "Date             0\n",
       "Open             0\n",
       "Promo            0\n",
       "StateHoliday     0\n",
       "SchoolHoliday    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records for the dates when stores were closed. \\\n",
    "WHY? \\\n",
    "To prevent bias\n",
    "HOW? \\\n",
    "1. Select indeces of records for the dates when stores were closed.\n",
    "2. Save information about promos and holidays on that dates.\n",
    "3. Fill the gaps in date range\n",
    "3. Fill the gaps in sales and customers values by interpolation\n",
    "4. Fill missing values in promos and holidays from the previously saved data where it's possible\n",
    "5. Fill left missing values with the nearest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 22:42:18,409 | INFO : Shape before removal: (5652, 9)\n",
      "2021-02-24 22:42:18,489 | INFO : Shape after removal: (4842, 9)\n",
      "2021-02-24 22:42:18,519 | INFO : Shape after filling date gaps: (5647, 9)\n",
      "2021-02-24 22:42:18,729 | INFO : Number of missing values in df: 0\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocessing_utils.interpolate_sales_customers(train_df, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4602.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4798.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  DayOfWeek   Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0 2013-01-02      9        3.0  4903.0      481.0   1.0    0.0            0   \n",
       "1 2013-01-03      9        4.0  4602.0      453.0   1.0    0.0            0   \n",
       "2 2013-01-04      9        5.0  4798.0      497.0   1.0    0.0            0   \n",
       "3 2013-01-05      9        6.0  4254.0      450.0   1.0    0.0            0   \n",
       "4 2013-01-06      9        6.0  4254.0      450.0   0.0    0.0            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            1.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 22:42:18,790 | INFO : Fill NaN in CompetitionDistance, CompetitionOpenSinceMonth, CompetitionOpenSinceYear with 0\n",
      "2021-02-24 22:42:18,795 | INFO : Fill NaN in Promo2SinceWeek, Promo2SinceYear with 0\n",
      "2021-02-24 22:42:18,797 | INFO : Fill NaN in PromoInterval with \"\"\n"
     ]
    }
   ],
   "source": [
    "store_df = preprocessing_utils.fill_nans_store_df(store_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'largefiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 22:42:18,859 | INFO : Encode labels in ['StoreType', 'Assortment', 'PromoInterval']\n",
      "2021-02-24 22:42:18,865 | INFO : Transform log1p CompetitionDistance\n",
      "2021-02-24 22:42:18,866 | INFO : Transform date features\n",
      "2021-02-24 22:42:18,874 | INFO : Save label encoder to largefiles/store_cat_cols_le.pkl\n"
     ]
    }
   ],
   "source": [
    "store_df, store_label_encoder = preprocessing_utils.transform_store_df(store_df, DATA_PATH + 'store_cat_cols_le')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StoreType': {'a': 0, 'b': 1, 'd': 2},\n",
       " 'Assortment': {'a': 0, 'c': 1},\n",
       " 'PromoInterval': {'': 0, 'Feb,May,Aug,Nov': 1, 'Jan,Apr,Jul,Oct': 2}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Sales'] = np.nan\n",
    "test_df['Customers'] = np.nan\n",
    "sales_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'b', 'a', 'c'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['StateHoliday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 22:42:19,640 | INFO : Add Day, Month, Year features\n",
      "2021-02-24 22:42:19,653 | INFO : Transform date features\n",
      "2021-02-24 22:42:19,672 | INFO : Encode StateHoliday\n",
      "2021-02-24 22:42:19,673 | INFO : Encode labels in ['StateHoliday']\n",
      "2021-02-24 22:42:19,676 | INFO : Save label encoder to largefiles/sales_cat_cols_le.pkl\n"
     ]
    }
   ],
   "source": [
    "sales_df, sales_label_encoder = preprocessing_utils.transform_sales_df(sales_df, DATA_PATH + 'sales_cat_cols_le')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sales_df.merge(store_df, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Year', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 23)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                               0\n",
       "Store                              0\n",
       "Sales                            144\n",
       "Customers                        144\n",
       "Open                               0\n",
       "Promo                              0\n",
       "StateHoliday                       0\n",
       "SchoolHoliday                      0\n",
       "DayOfWeek_sin                      0\n",
       "DayOfWeek_cos                      0\n",
       "Month_sin                          0\n",
       "Month_cos                          0\n",
       "Day_sin                            0\n",
       "Day_cos                            0\n",
       "StoreType                          0\n",
       "Assortment                         0\n",
       "CompetitionDistance                0\n",
       "Promo2                             0\n",
       "PromoInterval                      0\n",
       "CompetitionOpenSinceMonth_sin      0\n",
       "CompetitionOpenSinceMonth_cos      0\n",
       "Promo2SinceWeek_sin                0\n",
       "Promo2SinceWeek_cos                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(DATA_PATH + 'unscaled_sales_data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation strategy: Side-by-side split\\\n",
    "Dataset splits into independent parts, one part used strictly for training and another part used strictly for validation.\n",
    "\n",
    "Data range 2013 to 2015-07-31. \\\n",
    "Validation Model is trained on 2013 to 2015 data and predict 47 days of 2015 data.\n",
    "The best performing model will be trained on 2013 to 2015-07-31 data to predict 47 days from 2015-08-01 without validation. \\\n",
    "\n",
    "In the validation model sequences of the last 47 days of 2014 shouldn't be included because it contains 2015 values in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-01-01 00:00:00')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-09-17 00:00:00')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_range = pd.date_range(data['Date'].min(), data['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08',\n",
       "               '2013-01-09', '2013-01-10',\n",
       "               ...\n",
       "               '2014-11-05', '2014-11-06', '2014-11-07', '2014-11-08',\n",
       "               '2014-11-09', '2014-11-10', '2014-11-11', '2014-11-12',\n",
       "               '2014-11-13', '2014-11-14'],\n",
       "              dtype='datetime64[ns]', length=683, freq='D')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_range[full_range<'2014-11-15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = {'td': ['Sales', 'Customers'],\n",
    "                 'ti': ['Assortment', 'CompetitionDistance']\n",
    "                }\n",
    "val_date = None\n",
    "mode = 'val'\n",
    "if mode == 'val':\n",
    "    val_date = '2014-11-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 22:42:23,821 | INFO : Log Transform Sales and Customers\n",
      "2021-02-24 22:42:23,824 | INFO : Select records for scaler fitting\n",
      "2021-02-24 22:42:23,827 | INFO : Start scaling time-dependant features ['Sales', 'Customers']\n",
      "100%|██████████| 6/6 [00:00<00:00, 148.36it/s]\n",
      "2021-02-24 22:42:23,872 | INFO : Start scaling time-independant features ['Assortment', 'CompetitionDistance']\n",
      "2021-02-24 22:42:23,878 | INFO : Convert data formats to reduce memory usage\n",
      "2021-02-24 22:42:23,898 | INFO : Save pickle files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.30 Mb (74.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "scaled_data, scale_map = preprocessing_utils.scale_data(data,\n",
    "                                                        DATA_PATH + f'scalemap',\n",
    "                                                        DATA_PATH + f'scaled_data_{mode}',\n",
    "                                                        cols_to_scale,\n",
    "                                                        mode=mode,\n",
    "                                                        val_date=val_date\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Sales', 'Customers', 'Assortment', 'CompetitionDistance'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Sales': {9: {'mean': 8.698446806012091,\n",
       "               'std': 0.21241408104535603},\n",
       "              27: {'mean': 9.069292728673293, 'std': 0.2785646839764025},\n",
       "              54: {'mean': 8.950231782941518, 'std': 0.25856540963150454},\n",
       "              60: {'mean': 8.824867240665789, 'std': 0.3493825482362737},\n",
       "              61: {'mean': 8.395480646542113, 'std': 0.24033800225823132},\n",
       "              85: {'mean': 8.835683910199192, 'std': 0.27832203848658926}},\n",
       "             'Customers': {9: {'mean': 6.301670273679112,\n",
       "               'std': 0.15816774244446768},\n",
       "              27: {'mean': 6.937085932581848, 'std': 0.19657407654957232},\n",
       "              54: {'mean': 6.604266384908505, 'std': 0.22135019673784287},\n",
       "              60: {'mean': 6.4420359920103545, 'std': 0.3086576955564969},\n",
       "              61: {'mean': 6.325612928919133, 'std': 0.18545449001164774},\n",
       "              85: {'mean': 6.8866478122433445, 'std': 0.24486004946622758}},\n",
       "             'Assortment': {'mean': 0.666503786953335,\n",
       "              'std': 0.471519680074731},\n",
       "             'CompetitionDistance': {'mean': 7.103422386417884,\n",
       "              'std': 1.6531080443004007}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scale_map['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scale_map['Assortment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build data sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Store', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday',\n",
       "       'SchoolHoliday', 'DayOfWeek_sin', 'DayOfWeek_cos', 'Month_sin',\n",
       "       'Month_cos', 'Day_sin', 'Day_cos', 'StoreType', 'Assortment',\n",
       "       'CompetitionDistance', 'Promo2', 'PromoInterval',\n",
       "       'CompetitionOpenSinceMonth_sin', 'CompetitionOpenSinceMonth_cos',\n",
       "       'Promo2SinceWeek_sin', 'Promo2SinceWeek_cos', 'Sales_mean',\n",
       "       'Customers_mean', 'Assortment_mean', 'CompetitionDistance_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 90\n",
    "input_data_filename = DATA_PATH + f'scaled_data_{mode}'\n",
    "output_data_filename = DATA_PATH + f'sequence_data_{mode}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'largefiles/scaled_data_val'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'largefiles/sequence_data_val'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2021-02-24 22:42:29,135 | INFO : largefiles/scaled_data_val\n",
      "2021-02-24 22:42:29,136 | INFO : Time-dependant features: ['Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'DayOfWeek_sin', 'DayOfWeek_cos', 'Month_sin', 'Month_cos', 'Day_sin', 'Day_cos']\n",
      "2021-02-24 22:42:29,136 | INFO : Time-independent features: ['Date', 'StoreType', 'Assortment', 'CompetitionDistance', 'Promo2', 'PromoInterval', 'CompetitionOpenSinceMonth_sin', 'CompetitionOpenSinceMonth_cos', 'Promo2SinceWeek_sin', 'Promo2SinceWeek_cos', 'Sales_mean', 'Customers_mean', 'Assortment_mean', 'CompetitionDistance_mean']\n",
      "2021-02-24 22:42:29,136 | INFO : Target Feature: Sales\n",
      "2021-02-24 22:42:29,136 | INFO : Load pickle file: largefiles/scaled_data_val\n",
      "2021-02-24 22:42:29,139 | INFO : Start building sequences\n",
      "\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.59s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.69s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.69s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  9.00s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:09<00:00,  9.06s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:09<00:00,  9.07s/it]\n",
      "\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:09<00:00,  1.52s/it]\u001b[A\n",
      "(4975, 17)\n",
      "2021-02-24 22:42:38,489 | INFO : Save data to largefiles/sequence_data_val\n",
      "0it [00:09, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "! python build_sequence.py 'largefiles/scaled_data_val' 'largefiles/sequence_data_val' 90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = general_utils.open_pickle_file(output_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing_utils import StoreDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-11-15'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('90 days 00:00:00')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2013-04-01') - pd.to_datetime('2013-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence_data = seq_data[seq_data['Date'] == '2015-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'val':\n",
    "    train_sequence_data = seq_data[(seq_data['Date'] >= '2013-04-01') & (seq_data['Date'] <= val_date)]\n",
    "    valid_sequence_data = seq_data[(seq_data['Date'] > val_date) & (seq_data['Date'] <= '2015-01-01')]\n",
    "else:    \n",
    "    train_sequence_data = seq_data[(seq_data['Date'] >= '2013-04-01') & (seq_data['Date'] <= '2015-07-31') ]\n",
    "    valid_sequence_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3559, 17) (282, 17) (3, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train_sequence_data.shape, valid_sequence_data.shape, test_sequence_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence_data.iloc[[0]]['y_sequence'].values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['StoreType', 'Promo2', 'PromoInterval']\n",
    "num_columns = ['CompetitionDistance', 'CompetitionOpenSinceMonth_sin', 'CompetitionOpenSinceMonth_cos',\n",
    "               'Promo2SinceWeek_sin', 'Promo2SinceWeek_cos', 'Sales_mean',\n",
    "               'Customers_mean', 'Assortment_mean', 'CompetitionDistance_mean'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2021-02-24 23:00:16,802 | INFO : Create Dataset object\n",
      "2021-02-24 23:00:16,803 | INFO : Create Dataset object\n",
      "2021-02-24 23:00:16,804 | INFO : Create Dataset object\n"
     ]
    }
   ],
   "source": [
    "train_dataset = StoreDataset(cat_columns=cat_columns, num_columns=num_columns, embed_vector_size=50, ohe_cat_columns=True )\n",
    "valid_dataset = StoreDataset(cat_columns=cat_columns, num_columns=num_columns, embed_vector_size=50, ohe_cat_columns=True )\n",
    "test_dataset = StoreDataset(cat_columns=cat_columns, num_columns=num_columns, embed_vector_size=50, ohe_cat_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 23:00:19,367 | INFO : Load data\n",
      "2021-02-24 23:00:19,368 | INFO : Load data\n",
      "2021-02-24 23:00:19,371 | INFO : Load data\n"
     ]
    }
   ],
   "source": [
    "train_dataset.load_sequence_data(train_sequence_data)\n",
    "valid_dataset.load_sequence_data(valid_sequence_data)\n",
    "test_dataset.load_sequence_data(test_sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.process_cat_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset.process_cat_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.process_cat_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_cat = {'le': len(num_columns), 'ohe' : sum([x for x in zip(*train_dataset.cat_embed_shape)][0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12 + len(num_columns) + len_cat['ohe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 9\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print(len(train_dataloader), len(valid_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "torch.Size([90, 29])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "print(len(X))\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9443, -0.7822,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.2432, -1.1602,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.0469, -0.5757,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.3513,  0.3662,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [ 0.3513,  0.3662,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.1847, -0.0288,  0.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2432, -1.1602,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.0469, -0.5757,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.6133, -1.2021,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.3513,  0.3662,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.1847, -0.0288,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.1847, -0.0288,  1.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.0469, -0.5757,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.6133, -1.2021,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.6133, -1.2021,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.1847, -0.0288,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.1847, -0.0288,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.8076, -0.4128,  1.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0997, -0.1108,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [ 0.4187,  0.5601,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.1084, -0.9688,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.7622,  0.5708,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [ 0.2727,  0.5708,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.2150, -0.0056,  1.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4187,  0.5601,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.1084, -0.9688,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.1084, -0.9688,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.2727,  0.5708,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.2150, -0.0056,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.2896, -0.2179,  1.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.1084, -0.9688,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-1.1084, -0.9688,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.6997, -0.1820,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.2150, -0.0056,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.2896, -0.2179,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [-0.5815, -0.3635,  1.0000,  ...,  1.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 47])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2), (2, 1), (2, 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(num_classes, output_size) for num_classes, output_size in train_dataset.cat_embed_shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(3, 2)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(2, 1)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:21, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.model_utils import RNNEncoder, DecoderCell, EncoderDecoderWrapper, TorchTrainer\n",
    "device = 'cpu'\n",
    "\n",
    "encoder = RNNEncoder(\n",
    "    input_feature_len=train_dataset[0][0].shape[1], \n",
    "    rnn_num_layers=32, \n",
    "    hidden_size=128,  \n",
    "    sequence_len=train_dataset[0][0].shape[0],\n",
    "    bidirectional=False,\n",
    "    device=device,\n",
    "    rnn_dropout=0.1\n",
    ")\n",
    "\n",
    "decoder_cell = DecoderCell(\n",
    "    input_feature_len=1,\n",
    "    hidden_size=128,\n",
    ")\n",
    "\n",
    "\n",
    "#loss_function = differentiable_smape_loss\n",
    "#loss_function = differentiable_smape_loss\n",
    "loss_function = nn.MSELoss()\n",
    "#loss_function = nn.SmoothL1Loss()\n",
    "# encoder_optimizer = COCOBBackprop(encoder.parameters(), weight_decay=0)\n",
    "# decoder_optimizer = COCOBBackprop(decoder_cell.parameters(), weight_decay=0)\n",
    "# encoder_optimizer = torch.optim.AdamW(encoder.parameters(), lr=2e-3, weight_decay=1e-)\n",
    "# decoder_optimizer = torch.optim.AdamW(decoder_cell.parameters(), lr=2e-3, weight_decay=1e-1)\n",
    "\n",
    "\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder_cell = decoder_cell.to(device)\n",
    "\n",
    "model = EncoderDecoderWrapper(\n",
    "    encoder,\n",
    "    decoder_cell,\n",
    "    output_size=train_dataset[0][1].shape[0],\n",
    "    teacher_forcing=0,\n",
    "    sequence_len=train_dataset[0][0].shape[0],\n",
    "    decoder_input=False,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "decoder_optimizer = optim.AdamW(decoder_cell.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "encoder_scheduler = optim.lr_scheduler.OneCycleLR(encoder_optimizer, max_lr=1e-3, steps_per_epoch=len(train_dataloader), epochs=6)\n",
    "decoder_scheduler = optim.lr_scheduler.OneCycleLR(decoder_optimizer, max_lr=1e-3, steps_per_epoch=len(train_dataloader), epochs=6)\n",
    "\n",
    "model_optimizer = optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.input_feature_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1847, -0.0288,  0.0000,  0.0000,  2.0000,  1.0000,  0.0000,  1.0000,\n",
       "         0.8662, -0.5000,  0.2013,  0.9795,  0.3103, -0.8662, -0.5000,  0.0000,\n",
       "         1.0000,  8.6953,  6.3008,  0.6665,  7.1016,  1.0000,  0.0000,  0.0000,\n",
       "         1.0000,  0.0000,  1.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1847],\n",
       "        [-0.1847],\n",
       "        [-0.8076],\n",
       "        [-1.6514],\n",
       "        [-1.2217],\n",
       "        [-0.8091],\n",
       "        [-0.8091],\n",
       "        [ 0.7476],\n",
       "        [ 0.0844],\n",
       "        [-1.0654],\n",
       "        [-0.1782],\n",
       "        [ 0.0488],\n",
       "        [-0.9736],\n",
       "        [-0.9736],\n",
       "        [-1.1787],\n",
       "        [-1.3115],\n",
       "        [-1.6426],\n",
       "        [-1.0459],\n",
       "        [-0.5259],\n",
       "        [-1.3184],\n",
       "        [-1.3184],\n",
       "        [ 0.4702],\n",
       "        [ 0.0743],\n",
       "        [-0.3188],\n",
       "        [-1.1455],\n",
       "        [-0.2830],\n",
       "        [-0.6245],\n",
       "        [-0.6245],\n",
       "        [ 1.0186],\n",
       "        [ 1.0186],\n",
       "        [ 1.0186],\n",
       "        [ 1.2012],\n",
       "        [ 0.7847],\n",
       "        [-0.2722],\n",
       "        [-0.2722],\n",
       "        [-0.5854],\n",
       "        [-0.9849],\n",
       "        [-0.0162],\n",
       "        [-0.0162],\n",
       "        [-0.0209],\n",
       "        [-0.8325],\n",
       "        [-0.8325],\n",
       "        [ 0.6650],\n",
       "        [ 0.3198],\n",
       "        [-0.2068],\n",
       "        [-0.4062],\n",
       "        [-0.3943],\n",
       "        [-0.6904],\n",
       "        [-0.6904],\n",
       "        [ 0.0921],\n",
       "        [ 0.0921],\n",
       "        [-1.1162],\n",
       "        [-1.9639],\n",
       "        [-1.1660],\n",
       "        [-0.3511],\n",
       "        [-0.3511],\n",
       "        [ 0.9043],\n",
       "        [ 0.0402],\n",
       "        [ 0.6382],\n",
       "        [ 0.6382],\n",
       "        [ 1.6611],\n",
       "        [-0.5596],\n",
       "        [-0.5596],\n",
       "        [ 0.9849],\n",
       "        [-0.2125],\n",
       "        [-0.7686],\n",
       "        [-0.8550],\n",
       "        [ 0.0511],\n",
       "        [-0.5200],\n",
       "        [-0.5200],\n",
       "        [-0.5518],\n",
       "        [-1.2871],\n",
       "        [-1.5537],\n",
       "        [-0.9668],\n",
       "        [-0.9292],\n",
       "        [-0.7646],\n",
       "        [-0.7646],\n",
       "        [ 1.1826],\n",
       "        [ 0.0371],\n",
       "        [-0.7446],\n",
       "        [-0.4902],\n",
       "        [-0.3909],\n",
       "        [-1.1123],\n",
       "        [-1.1123],\n",
       "        [-0.5859],\n",
       "        [-0.7793],\n",
       "        [-1.6113],\n",
       "        [-0.8682],\n",
       "        [-0.5269],\n",
       "        [ 0.0379],\n",
       "        [ 0.0379],\n",
       "        [ 1.3184],\n",
       "        [ 0.6978],\n",
       "        [ 0.1152],\n",
       "        [-0.2539],\n",
       "        [ 0.0176],\n",
       "        [-0.8560],\n",
       "        [-0.8560],\n",
       "        [-0.6440],\n",
       "        [-1.1240],\n",
       "        [-1.3535],\n",
       "        [-0.6812],\n",
       "        [-0.7461],\n",
       "        [-0.9053],\n",
       "        [-0.9053],\n",
       "        [ 2.0215],\n",
       "        [ 1.6875],\n",
       "        [ 1.0820],\n",
       "        [ 0.9507],\n",
       "        [ 1.2529],\n",
       "        [ 0.1753],\n",
       "        [ 0.1753],\n",
       "        [-0.7134],\n",
       "        [-0.7471],\n",
       "        [-1.0010],\n",
       "        [-0.8428],\n",
       "        [-0.8457],\n",
       "        [-1.7256],\n",
       "        [-1.7256],\n",
       "        [ 1.4463],\n",
       "        [ 0.3118],\n",
       "        [ 0.4287],\n",
       "        [ 0.2527],\n",
       "        [-0.1619],\n",
       "        [-0.9541],\n",
       "        [-0.9541],\n",
       "        [-0.4424],\n",
       "        [-0.9263],\n",
       "        [-1.1348],\n",
       "        [-1.1797],\n",
       "        [-0.6621],\n",
       "        [-1.0078],\n",
       "        [-1.0078],\n",
       "        [ 2.1074],\n",
       "        [-0.0280],\n",
       "        [-0.0653],\n",
       "        [-0.2913],\n",
       "        [-0.6011],\n",
       "        [-1.4365],\n",
       "        [-1.4365],\n",
       "        [-1.0078],\n",
       "        [-0.9102],\n",
       "        [-1.6992],\n",
       "        [-0.8159],\n",
       "        [-1.2793],\n",
       "        [-1.7959],\n",
       "        [-1.7959],\n",
       "        [ 1.8340],\n",
       "        [ 0.3250],\n",
       "        [-0.4165],\n",
       "        [ 0.5103],\n",
       "        [ 0.4209],\n",
       "        [-0.2820],\n",
       "        [-0.2820],\n",
       "        [ 0.3892],\n",
       "        [-0.8657],\n",
       "        [-0.4277],\n",
       "        [-1.2568],\n",
       "        [-0.6030],\n",
       "        [-0.5322],\n",
       "        [-0.5322],\n",
       "        [ 2.0410],\n",
       "        [ 0.1738],\n",
       "        [ 0.4666],\n",
       "        [-0.0997],\n",
       "        [ 0.4187],\n",
       "        [-1.1084],\n",
       "        [-1.1084],\n",
       "        [-0.6997],\n",
       "        [-1.0156],\n",
       "        [-1.1504],\n",
       "        [-1.1670],\n",
       "        [-0.9868],\n",
       "        [-1.0625],\n",
       "        [-1.0625],\n",
       "        [ 1.3027],\n",
       "        [-0.1102],\n",
       "        [-0.6685],\n",
       "        [-0.6533],\n",
       "        [-0.2771],\n",
       "        [-0.6914],\n",
       "        [-0.6914],\n",
       "        [ 0.3906],\n",
       "        [-0.0805],\n",
       "        [ 0.1503],\n",
       "        [ 0.1503],\n",
       "        [ 0.6802],\n",
       "        [-0.6333],\n",
       "        [-0.6333],\n",
       "        [ 1.9609],\n",
       "        [ 0.9233],\n",
       "        [ 0.1013],\n",
       "        [-0.3105],\n",
       "        [-0.2167],\n",
       "        [-0.0367],\n",
       "        [-0.0367],\n",
       "        [-0.4614],\n",
       "        [-1.3916],\n",
       "        [-0.3628],\n",
       "        [-1.5000],\n",
       "        [-0.8335],\n",
       "        [-0.8599],\n",
       "        [-0.8599],\n",
       "        [ 1.5381],\n",
       "        [-0.1700],\n",
       "        [-0.5225],\n",
       "        [-0.2200],\n",
       "        [-0.5952],\n",
       "        [-0.7656],\n",
       "        [-0.7656],\n",
       "        [-0.4546],\n",
       "        [-1.1895],\n",
       "        [-1.0439],\n",
       "        [ 0.1897],\n",
       "        [ 0.1897],\n",
       "        [ 0.4851],\n",
       "        [ 0.4851],\n",
       "        [ 1.7549],\n",
       "        [ 1.1299],\n",
       "        [ 0.0643],\n",
       "        [-0.4771],\n",
       "        [ 0.6313],\n",
       "        [ 0.1006],\n",
       "        [ 0.1006],\n",
       "        [-0.6021],\n",
       "        [-1.4961],\n",
       "        [-0.9766],\n",
       "        [-0.7915],\n",
       "        [-0.7832],\n",
       "        [-0.5747],\n",
       "        [-0.5747],\n",
       "        [ 1.4766],\n",
       "        [ 0.6733],\n",
       "        [ 0.2429],\n",
       "        [-0.1262],\n",
       "        [-0.0344],\n",
       "        [-0.3977],\n",
       "        [-0.3977],\n",
       "        [-0.8486],\n",
       "        [-0.8027],\n",
       "        [-0.8799],\n",
       "        [ 0.2085],\n",
       "        [-0.2019],\n",
       "        [ 1.3906],\n",
       "        [ 1.3906],\n",
       "        [ 1.7129],\n",
       "        [ 1.1865],\n",
       "        [ 0.3608],\n",
       "        [ 0.5356],\n",
       "        [ 0.3579],\n",
       "        [ 0.7622],\n",
       "        [ 0.7622],\n",
       "        [ 0.2727],\n",
       "        [-0.2150],\n",
       "        [-0.2896],\n",
       "        [-0.5815]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[:, -1, 0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 47])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dataloader))\n",
    "xb = xb.to(device)\n",
    "yb = yb.to(device)\n",
    "model(xb, yb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 28])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    'encdec_ohe_std_mse_wd1e-2_do2e-1_test_hs100_tf0_adam',\n",
    "    model, \n",
    "    [encoder_optimizer, decoder_optimizer], \n",
    "    loss_function, \n",
    "    [encoder_scheduler, decoder_scheduler],\n",
    "    device, \n",
    "    scheduler_batch_step=True,\n",
    "    pass_y=True,\n",
    "    #additional_metric_fns={'SMAPE': smape_exp_loss}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fadad6418845fca7b77a04f2c41eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 7.20E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.lr_find(train_dataloader, model_optimizer, start_lr=1e-5, end_lr=1e-2, num_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "loss 1.0534:   0%|          | 0/112 [00:02<?, ?it/s]\u001b[A\n",
      "loss 1.0534:   1%|          | 1/112 [00:02<04:41,  2.53s/it]\u001b[A\n",
      "loss 1.0482:   1%|          | 1/112 [00:05<04:41,  2.53s/it]\u001b[A\n",
      "loss 1.0482:   2%|▏         | 2/112 [00:05<05:34,  3.05s/it]\u001b[A\n",
      "loss 1.0479:   2%|▏         | 2/112 [00:08<05:34,  3.05s/it]\u001b[A\n",
      "loss 1.0479:   3%|▎         | 3/112 [00:08<05:28,  3.01s/it]\u001b[A\n",
      "loss 1.0208:   3%|▎         | 3/112 [00:11<05:28,  3.01s/it]\u001b[A\n",
      "loss 1.0208:   4%|▎         | 4/112 [00:11<05:04,  2.82s/it]\u001b[A\n",
      "loss 1.0158:   4%|▎         | 4/112 [00:13<05:04,  2.82s/it]\u001b[A\n",
      "loss 1.0158:   4%|▍         | 5/112 [00:13<04:47,  2.68s/it]\u001b[A\n",
      "loss 0.9718:   4%|▍         | 5/112 [00:15<04:47,  2.68s/it]\u001b[A\n",
      "loss 0.9718:   5%|▌         | 6/112 [00:15<04:23,  2.49s/it]\u001b[A\n",
      "loss 0.9656:   5%|▌         | 6/112 [00:18<04:23,  2.49s/it]\u001b[A\n",
      "loss 0.9656:   6%|▋         | 7/112 [00:18<04:07,  2.36s/it]\u001b[A\n",
      "loss 1.0049:   6%|▋         | 7/112 [00:20<04:07,  2.36s/it]\u001b[A\n",
      "loss 1.0049:   7%|▋         | 8/112 [00:20<03:59,  2.31s/it]\u001b[A\n",
      "loss 1.0428:   7%|▋         | 8/112 [00:22<03:59,  2.31s/it]\u001b[A\n",
      "loss 1.0428:   8%|▊         | 9/112 [00:22<03:50,  2.24s/it]\u001b[A\n",
      "loss 1.1011:   8%|▊         | 9/112 [00:24<03:50,  2.24s/it]\u001b[A\n",
      "loss 1.1011:   9%|▉         | 10/112 [00:24<03:44,  2.20s/it]\u001b[A\n",
      "loss 0.9551:   9%|▉         | 10/112 [00:26<03:44,  2.20s/it]\u001b[A\n",
      "loss 0.9551:  10%|▉         | 11/112 [00:26<03:42,  2.20s/it]\u001b[A\n",
      "loss 1.0586:  10%|▉         | 11/112 [00:28<03:42,  2.20s/it]\u001b[A\n",
      "loss 1.0586:  11%|█         | 12/112 [00:28<03:34,  2.15s/it]\u001b[A\n",
      "loss 1.0414:  11%|█         | 12/112 [00:30<03:34,  2.15s/it]\u001b[A\n",
      "loss 1.0414:  12%|█▏        | 13/112 [00:30<03:30,  2.13s/it]\u001b[A\n",
      "loss 1.0741:  12%|█▏        | 13/112 [00:33<03:30,  2.13s/it]\u001b[A\n",
      "loss 1.0741:  12%|█▎        | 14/112 [00:33<03:32,  2.17s/it]\u001b[A\n",
      "loss 0.9293:  12%|█▎        | 14/112 [00:35<03:32,  2.17s/it]\u001b[A\n",
      "loss 0.9293:  13%|█▎        | 15/112 [00:35<03:32,  2.19s/it]\u001b[A\n",
      "loss 0.9104:  13%|█▎        | 15/112 [00:37<03:32,  2.19s/it]\u001b[A\n",
      "loss 0.9104:  14%|█▍        | 16/112 [00:37<03:26,  2.15s/it]\u001b[A\n",
      "loss 0.9956:  14%|█▍        | 16/112 [00:39<03:26,  2.15s/it]\u001b[A\n",
      "loss 0.9956:  15%|█▌        | 17/112 [00:39<03:26,  2.18s/it]\u001b[A\n",
      "loss 1.0145:  15%|█▌        | 17/112 [00:41<03:26,  2.18s/it]\u001b[A\n",
      "loss 1.0145:  16%|█▌        | 18/112 [00:41<03:19,  2.13s/it]\u001b[A\n",
      "loss 1.0688:  16%|█▌        | 18/112 [00:43<03:19,  2.13s/it]\u001b[A\n",
      "loss 1.0688:  17%|█▋        | 19/112 [00:43<03:16,  2.11s/it]\u001b[A\n",
      "loss 1.0234:  17%|█▋        | 19/112 [00:45<03:16,  2.11s/it]\u001b[A\n",
      "loss 1.0234:  18%|█▊        | 20/112 [00:45<03:17,  2.15s/it]\u001b[A\n",
      "loss 0.9192:  18%|█▊        | 20/112 [00:48<03:17,  2.15s/it]\u001b[A\n",
      "loss 0.9192:  19%|█▉        | 21/112 [00:48<03:13,  2.13s/it]\u001b[A\n",
      "loss 1.0134:  19%|█▉        | 21/112 [00:50<03:13,  2.13s/it]\u001b[A\n",
      "loss 1.0134:  20%|█▉        | 22/112 [00:50<03:13,  2.15s/it]\u001b[A\n",
      "loss 0.9084:  20%|█▉        | 22/112 [00:52<03:13,  2.15s/it]\u001b[A\n",
      "loss 0.9084:  21%|██        | 23/112 [00:52<03:14,  2.18s/it]\u001b[A\n",
      "loss 0.9453:  21%|██        | 23/112 [00:54<03:14,  2.18s/it]\u001b[A\n",
      "loss 0.9453:  21%|██▏       | 24/112 [00:54<03:09,  2.15s/it]\u001b[A\n",
      "loss 0.9582:  21%|██▏       | 24/112 [00:57<03:09,  2.15s/it]\u001b[A\n",
      "loss 0.9582:  22%|██▏       | 25/112 [00:57<03:23,  2.34s/it]\u001b[A\n",
      "loss 1.0603:  22%|██▏       | 25/112 [00:59<03:23,  2.34s/it]\u001b[A\n",
      "loss 1.0603:  23%|██▎       | 26/112 [00:59<03:21,  2.35s/it]\u001b[A\n",
      "loss 1.0158:  23%|██▎       | 26/112 [01:01<03:21,  2.35s/it]\u001b[A\n",
      "loss 1.0158:  24%|██▍       | 27/112 [01:01<03:15,  2.30s/it]\u001b[A\n",
      "loss 0.9134:  24%|██▍       | 27/112 [01:04<03:15,  2.30s/it]\u001b[A\n",
      "loss 0.9134:  25%|██▌       | 28/112 [01:04<03:14,  2.32s/it]\u001b[A\n",
      "loss 0.9539:  25%|██▌       | 28/112 [01:06<03:14,  2.32s/it]\u001b[A\n",
      "loss 0.9539:  26%|██▌       | 29/112 [01:06<03:10,  2.30s/it]\u001b[A\n",
      "loss 0.9957:  26%|██▌       | 29/112 [01:08<03:10,  2.30s/it]\u001b[A\n",
      "loss 0.9957:  27%|██▋       | 30/112 [01:08<03:07,  2.29s/it]\u001b[A\n",
      "loss 1.0205:  27%|██▋       | 30/112 [01:10<03:07,  2.29s/it]\u001b[A\n",
      "loss 1.0205:  28%|██▊       | 31/112 [01:10<03:00,  2.23s/it]\u001b[A\n",
      "loss 0.9628:  28%|██▊       | 31/112 [01:13<03:00,  2.23s/it]\u001b[A\n",
      "loss 0.9628:  29%|██▊       | 32/112 [01:13<02:57,  2.22s/it]\u001b[A\n",
      "loss 0.9755:  29%|██▊       | 32/112 [01:15<02:57,  2.22s/it]\u001b[A\n",
      "loss 0.9755:  29%|██▉       | 33/112 [01:15<02:54,  2.21s/it]\u001b[A\n",
      "loss 0.9804:  29%|██▉       | 33/112 [01:17<02:54,  2.21s/it]\u001b[A\n",
      "loss 0.9804:  30%|███       | 34/112 [01:17<02:47,  2.15s/it]\u001b[A\n",
      "loss 0.9831:  30%|███       | 34/112 [01:19<02:47,  2.15s/it]\u001b[A\n",
      "loss 0.9831:  31%|███▏      | 35/112 [01:19<02:41,  2.10s/it]\u001b[A\n",
      "loss 1.0724:  31%|███▏      | 35/112 [01:21<02:41,  2.10s/it]\u001b[A\n",
      "loss 1.0724:  32%|███▏      | 36/112 [01:21<02:37,  2.08s/it]\u001b[A\n",
      "loss 0.9425:  32%|███▏      | 36/112 [01:23<02:37,  2.08s/it]\u001b[A\n",
      "loss 0.9425:  33%|███▎      | 37/112 [01:23<02:39,  2.13s/it]\u001b[A\n",
      "loss 0.8781:  33%|███▎      | 37/112 [01:25<02:39,  2.13s/it]\u001b[A\n",
      "loss 0.8781:  34%|███▍      | 38/112 [01:25<02:41,  2.19s/it]\u001b[A\n",
      "loss 0.9758:  34%|███▍      | 38/112 [01:27<02:41,  2.19s/it]\u001b[A\n",
      "loss 0.9758:  35%|███▍      | 39/112 [01:27<02:37,  2.15s/it]\u001b[A\n",
      "loss 0.9921:  35%|███▍      | 39/112 [01:29<02:37,  2.15s/it]\u001b[A\n",
      "loss 0.9921:  36%|███▌      | 40/112 [01:29<02:33,  2.14s/it]\u001b[A\n",
      "loss 1.1033:  36%|███▌      | 40/112 [01:32<02:33,  2.14s/it]\u001b[A\n",
      "loss 1.1033:  37%|███▋      | 41/112 [01:32<02:30,  2.12s/it]\u001b[A\n",
      "loss 0.9775:  37%|███▋      | 41/112 [01:34<02:30,  2.12s/it]\u001b[A\n",
      "loss 0.9775:  38%|███▊      | 42/112 [01:34<02:27,  2.11s/it]\u001b[A\n",
      "loss 1.0030:  38%|███▊      | 42/112 [01:37<02:27,  2.11s/it]\u001b[A\n",
      "loss 1.0030:  38%|███▊      | 43/112 [01:37<02:44,  2.39s/it]\u001b[A\n",
      "loss 0.9311:  38%|███▊      | 43/112 [01:40<02:44,  2.39s/it]\u001b[A\n",
      "loss 0.9311:  39%|███▉      | 44/112 [01:40<03:05,  2.72s/it]\u001b[A\n",
      "loss 0.9755:  39%|███▉      | 44/112 [01:44<03:05,  2.72s/it]\u001b[A\n",
      "loss 0.9755:  40%|████      | 45/112 [01:44<03:14,  2.90s/it]\u001b[A\n",
      "loss 0.9659:  40%|████      | 45/112 [01:46<03:14,  2.90s/it]\u001b[A\n",
      "loss 0.9659:  41%|████      | 46/112 [01:46<02:58,  2.70s/it]\u001b[A\n",
      "loss 0.9390:  41%|████      | 46/112 [01:48<02:58,  2.70s/it]\u001b[A\n",
      "loss 0.9390:  42%|████▏     | 47/112 [01:48<02:46,  2.56s/it]\u001b[A\n",
      "loss 1.1031:  42%|████▏     | 47/112 [01:50<02:46,  2.56s/it]\u001b[A\n",
      "loss 1.1031:  43%|████▎     | 48/112 [01:50<02:34,  2.42s/it]\u001b[A\n",
      "loss 0.9075:  43%|████▎     | 48/112 [01:52<02:34,  2.42s/it]\u001b[A\n",
      "loss 0.9075:  44%|████▍     | 49/112 [01:52<02:25,  2.31s/it]\u001b[A\n",
      "loss 0.9999:  44%|████▍     | 49/112 [01:54<02:25,  2.31s/it]\u001b[A\n",
      "loss 0.9999:  45%|████▍     | 50/112 [01:54<02:18,  2.24s/it]\u001b[A\n",
      "loss 1.1137:  45%|████▍     | 50/112 [01:56<02:18,  2.24s/it]\u001b[A\n",
      "loss 1.1137:  46%|████▌     | 51/112 [01:56<02:17,  2.25s/it]\u001b[A\n",
      "loss 1.0721:  46%|████▌     | 51/112 [01:59<02:17,  2.25s/it]\u001b[A\n",
      "loss 1.0721:  46%|████▋     | 52/112 [01:59<02:11,  2.18s/it]\u001b[A\n",
      "loss 0.9853:  46%|████▋     | 52/112 [02:01<02:11,  2.18s/it]\u001b[A\n",
      "loss 0.9853:  47%|████▋     | 53/112 [02:01<02:13,  2.26s/it]\u001b[A\n",
      "loss 0.9363:  47%|████▋     | 53/112 [02:03<02:13,  2.26s/it]\u001b[A\n",
      "loss 0.9363:  48%|████▊     | 54/112 [02:03<02:12,  2.28s/it]\u001b[A\n",
      "loss 1.0505:  48%|████▊     | 54/112 [02:06<02:12,  2.28s/it]\u001b[A\n",
      "loss 1.0505:  49%|████▉     | 55/112 [02:06<02:09,  2.27s/it]\u001b[A\n",
      "loss 1.0313:  49%|████▉     | 55/112 [02:08<02:09,  2.27s/it]\u001b[A\n",
      "loss 1.0313:  50%|█████     | 56/112 [02:08<02:15,  2.43s/it]\u001b[A\n",
      "loss 0.9457:  50%|█████     | 56/112 [02:12<02:15,  2.43s/it]\u001b[A\n",
      "loss 0.9457:  51%|█████     | 57/112 [02:12<02:29,  2.71s/it]\u001b[A\n",
      "loss 0.9945:  51%|█████     | 57/112 [02:15<02:29,  2.71s/it]\u001b[A\n",
      "loss 0.9945:  52%|█████▏    | 58/112 [02:15<02:43,  3.03s/it]\u001b[A\n",
      "loss 1.0225:  52%|█████▏    | 58/112 [02:18<02:43,  3.03s/it]\u001b[A\n",
      "loss 1.0225:  53%|█████▎    | 59/112 [02:18<02:35,  2.93s/it]\u001b[A\n",
      "loss 1.0838:  53%|█████▎    | 59/112 [02:20<02:35,  2.93s/it]\u001b[A\n",
      "loss 1.0838:  54%|█████▎    | 60/112 [02:20<02:20,  2.71s/it]\u001b[A\n",
      "loss 0.9265:  54%|█████▎    | 60/112 [02:23<02:20,  2.71s/it]\u001b[A\n",
      "loss 0.9265:  54%|█████▍    | 61/112 [02:23<02:09,  2.55s/it]\u001b[A\n",
      "loss 0.9716:  54%|█████▍    | 61/112 [02:25<02:09,  2.55s/it]\u001b[A\n",
      "loss 0.9716:  55%|█████▌    | 62/112 [02:25<02:07,  2.55s/it]\u001b[A\n",
      "loss 1.0381:  55%|█████▌    | 62/112 [02:27<02:07,  2.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 1.0381:  56%|█████▋    | 63/112 [02:27<02:01,  2.47s/it]\u001b[A\n",
      "loss 0.9497:  56%|█████▋    | 63/112 [02:30<02:01,  2.47s/it]\u001b[A\n",
      "loss 0.9497:  57%|█████▋    | 64/112 [02:30<02:04,  2.59s/it]\u001b[A\n",
      "loss 1.0278:  57%|█████▋    | 64/112 [02:34<02:04,  2.59s/it]\u001b[A\n",
      "loss 1.0278:  58%|█████▊    | 65/112 [02:34<02:12,  2.82s/it]\u001b[A\n",
      "loss 0.9581:  58%|█████▊    | 65/112 [02:36<02:12,  2.82s/it]\u001b[A\n",
      "loss 0.9581:  59%|█████▉    | 66/112 [02:36<02:02,  2.65s/it]\u001b[A\n",
      "loss 1.0256:  59%|█████▉    | 66/112 [02:38<02:02,  2.65s/it]\u001b[A\n",
      "loss 1.0256:  60%|█████▉    | 67/112 [02:38<01:50,  2.45s/it]\u001b[A\n",
      "loss 0.8966:  60%|█████▉    | 67/112 [02:40<01:50,  2.45s/it]\u001b[A\n",
      "loss 0.8966:  61%|██████    | 68/112 [02:40<01:43,  2.36s/it]\u001b[A\n",
      "loss 1.0085:  61%|██████    | 68/112 [02:43<01:43,  2.36s/it]\u001b[A\n",
      "loss 1.0085:  62%|██████▏   | 69/112 [02:43<01:55,  2.70s/it]\u001b[A\n",
      "loss 1.0470:  62%|██████▏   | 69/112 [02:46<01:55,  2.70s/it]\u001b[A\n",
      "loss 1.0470:  62%|██████▎   | 70/112 [02:46<01:45,  2.51s/it]\u001b[A\n",
      "loss 0.9721:  62%|██████▎   | 70/112 [02:47<01:45,  2.51s/it]\u001b[A\n",
      "loss 0.9721:  63%|██████▎   | 71/112 [02:47<01:35,  2.34s/it]\u001b[A\n",
      "loss 1.0023:  63%|██████▎   | 71/112 [02:50<01:35,  2.34s/it]\u001b[A\n",
      "loss 1.0023:  64%|██████▍   | 72/112 [02:50<01:34,  2.36s/it]\u001b[A\n",
      "loss 1.0527:  64%|██████▍   | 72/112 [02:52<01:34,  2.36s/it]\u001b[A\n",
      "loss 1.0527:  65%|██████▌   | 73/112 [02:52<01:30,  2.33s/it]\u001b[A\n",
      "loss 0.8843:  65%|██████▌   | 73/112 [02:54<01:30,  2.33s/it]\u001b[A\n",
      "loss 0.8843:  66%|██████▌   | 74/112 [02:54<01:26,  2.28s/it]\u001b[A\n",
      "loss 1.0335:  66%|██████▌   | 74/112 [02:57<01:26,  2.28s/it]\u001b[A\n",
      "loss 1.0335:  67%|██████▋   | 75/112 [02:57<01:25,  2.31s/it]\u001b[A\n",
      "loss 0.9436:  67%|██████▋   | 75/112 [03:01<01:25,  2.31s/it]\u001b[A\n",
      "loss 0.9436:  68%|██████▊   | 76/112 [03:01<01:40,  2.78s/it]\u001b[A\n",
      "loss 0.9413:  68%|██████▊   | 76/112 [03:04<01:40,  2.78s/it]\u001b[A\n",
      "loss 0.9413:  69%|██████▉   | 77/112 [03:04<01:39,  2.85s/it]\u001b[A\n",
      "loss 0.9117:  69%|██████▉   | 77/112 [03:08<01:39,  2.85s/it]\u001b[A\n",
      "loss 0.9117:  70%|██████▉   | 78/112 [03:08<01:48,  3.18s/it]\u001b[A\n",
      "loss 0.9620:  70%|██████▉   | 78/112 [03:11<01:48,  3.18s/it]\u001b[A\n",
      "loss 0.9620:  71%|███████   | 79/112 [03:11<01:44,  3.16s/it]\u001b[A\n",
      "loss 1.0688:  71%|███████   | 79/112 [03:14<01:44,  3.16s/it]\u001b[A\n",
      "loss 1.0688:  71%|███████▏  | 80/112 [03:14<01:41,  3.17s/it]\u001b[A\n",
      "loss 0.9967:  71%|███████▏  | 80/112 [03:17<01:41,  3.17s/it]\u001b[A\n",
      "loss 0.9967:  72%|███████▏  | 81/112 [03:17<01:37,  3.15s/it]\u001b[A\n",
      "loss 1.0023:  72%|███████▏  | 81/112 [03:19<01:37,  3.15s/it]\u001b[A\n",
      "loss 1.0023:  73%|███████▎  | 82/112 [03:19<01:27,  2.93s/it]\u001b[A\n",
      "loss 0.9579:  73%|███████▎  | 82/112 [03:22<01:27,  2.93s/it]\u001b[A\n",
      "loss 0.9579:  74%|███████▍  | 83/112 [03:22<01:21,  2.80s/it]\u001b[A\n",
      "loss 0.9273:  74%|███████▍  | 83/112 [03:25<01:21,  2.80s/it]\u001b[A\n",
      "loss 0.9273:  75%|███████▌  | 84/112 [03:25<01:19,  2.86s/it]\u001b[A\n",
      "loss 1.1353:  75%|███████▌  | 84/112 [03:27<01:19,  2.86s/it]\u001b[A\n",
      "loss 1.1353:  76%|███████▌  | 85/112 [03:27<01:13,  2.71s/it]\u001b[A\n",
      "loss 1.0933:  76%|███████▌  | 85/112 [03:30<01:13,  2.71s/it]\u001b[A\n",
      "loss 1.0933:  77%|███████▋  | 86/112 [03:30<01:07,  2.60s/it]\u001b[A\n",
      "loss 0.9151:  77%|███████▋  | 86/112 [03:32<01:07,  2.60s/it]\u001b[A\n",
      "loss 0.9151:  78%|███████▊  | 87/112 [03:32<01:01,  2.46s/it]\u001b[A\n",
      "loss 0.9204:  78%|███████▊  | 87/112 [03:34<01:01,  2.46s/it]\u001b[A\n",
      "loss 0.9204:  79%|███████▊  | 88/112 [03:34<00:56,  2.36s/it]\u001b[A\n",
      "loss 1.0988:  79%|███████▊  | 88/112 [03:36<00:56,  2.36s/it]\u001b[A\n",
      "loss 1.0988:  79%|███████▉  | 89/112 [03:36<00:52,  2.29s/it]\u001b[A\n",
      "loss 0.8864:  79%|███████▉  | 89/112 [03:38<00:52,  2.29s/it]\u001b[A\n",
      "loss 0.8864:  80%|████████  | 90/112 [03:38<00:48,  2.22s/it]\u001b[A\n",
      "loss 0.9035:  80%|████████  | 90/112 [03:40<00:48,  2.22s/it]\u001b[A\n",
      "loss 0.9035:  81%|████████▏ | 91/112 [03:40<00:46,  2.21s/it]\u001b[A\n",
      "loss 1.0154:  81%|████████▏ | 91/112 [03:44<00:46,  2.21s/it]\u001b[A\n",
      "loss 1.0154:  82%|████████▏ | 92/112 [03:44<00:51,  2.59s/it]\u001b[A\n",
      "loss 0.9103:  82%|████████▏ | 92/112 [03:47<00:51,  2.59s/it]\u001b[A\n",
      "loss 0.9103:  83%|████████▎ | 93/112 [03:47<00:53,  2.79s/it]\u001b[A\n",
      "loss 0.8857:  83%|████████▎ | 93/112 [03:49<00:53,  2.79s/it]\u001b[A\n",
      "loss 0.8857:  84%|████████▍ | 94/112 [03:49<00:46,  2.59s/it]\u001b[A\n",
      "loss 0.9534:  84%|████████▍ | 94/112 [03:51<00:46,  2.59s/it]\u001b[A\n",
      "loss 0.9534:  85%|████████▍ | 95/112 [03:51<00:40,  2.40s/it]\u001b[A\n",
      "loss 0.9592:  85%|████████▍ | 95/112 [03:53<00:40,  2.40s/it]\u001b[A\n",
      "loss 0.9592:  86%|████████▌ | 96/112 [03:53<00:36,  2.28s/it]\u001b[A\n",
      "loss 1.0739:  86%|████████▌ | 96/112 [03:57<00:36,  2.28s/it]\u001b[A\n",
      "loss 1.0739:  87%|████████▋ | 97/112 [03:57<00:40,  2.68s/it]\u001b[A\n",
      "loss 1.0589:  87%|████████▋ | 97/112 [04:00<00:40,  2.68s/it]\u001b[A\n",
      "loss 1.0589:  88%|████████▊ | 98/112 [04:00<00:38,  2.78s/it]\u001b[A\n",
      "loss 0.9689:  88%|████████▊ | 98/112 [04:03<00:38,  2.78s/it]\u001b[A\n",
      "loss 0.9689:  88%|████████▊ | 99/112 [04:03<00:37,  2.91s/it]\u001b[A\n",
      "loss 0.9662:  88%|████████▊ | 99/112 [04:05<00:37,  2.91s/it]\u001b[A\n",
      "loss 0.9662:  89%|████████▉ | 100/112 [04:05<00:32,  2.73s/it]\u001b[A\n",
      "loss 1.0760:  89%|████████▉ | 100/112 [04:07<00:32,  2.73s/it]\u001b[A\n",
      "loss 1.0760:  90%|█████████ | 101/112 [04:07<00:27,  2.53s/it]\u001b[A\n",
      "loss 1.0758:  90%|█████████ | 101/112 [04:09<00:27,  2.53s/it]\u001b[A\n",
      "loss 1.0758:  91%|█████████ | 102/112 [04:09<00:24,  2.41s/it]\u001b[A\n",
      "loss 0.9862:  91%|█████████ | 102/112 [04:11<00:24,  2.41s/it]\u001b[A\n",
      "loss 0.9862:  92%|█████████▏| 103/112 [04:11<00:20,  2.30s/it]\u001b[A\n",
      "loss 1.1272:  92%|█████████▏| 103/112 [04:14<00:20,  2.30s/it]\u001b[A\n",
      "loss 1.1272:  93%|█████████▎| 104/112 [04:14<00:18,  2.28s/it]\u001b[A\n",
      "loss 0.9804:  93%|█████████▎| 104/112 [04:16<00:18,  2.28s/it]\u001b[A\n",
      "loss 0.9804:  94%|█████████▍| 105/112 [04:16<00:15,  2.24s/it]\u001b[A\n",
      "loss 0.9669:  94%|█████████▍| 105/112 [04:18<00:15,  2.24s/it]\u001b[A\n",
      "loss 0.9669:  95%|█████████▍| 106/112 [04:18<00:13,  2.17s/it]\u001b[A\n",
      "loss 1.0155:  95%|█████████▍| 106/112 [04:20<00:13,  2.17s/it]\u001b[A\n",
      "loss 1.0155:  96%|█████████▌| 107/112 [04:20<00:10,  2.14s/it]\u001b[A\n",
      "loss 1.0063:  96%|█████████▌| 107/112 [04:22<00:10,  2.14s/it]\u001b[A\n",
      "loss 1.0063:  96%|█████████▋| 108/112 [04:22<00:08,  2.17s/it]\u001b[A\n",
      "loss 0.9951:  96%|█████████▋| 108/112 [04:24<00:08,  2.17s/it]\u001b[A\n",
      "loss 0.9951:  97%|█████████▋| 109/112 [04:24<00:06,  2.17s/it]\u001b[A\n",
      "loss 1.1771:  97%|█████████▋| 109/112 [04:27<00:06,  2.17s/it]\u001b[A\n",
      "loss 1.1771:  98%|█████████▊| 110/112 [04:27<00:04,  2.21s/it]\u001b[A\n",
      "loss 1.0258:  98%|█████████▊| 110/112 [04:29<00:04,  2.21s/it]\u001b[A\n",
      "loss 1.0258:  99%|█████████▉| 111/112 [04:29<00:02,  2.26s/it]\u001b[A\n",
      "loss 0.9407:  99%|█████████▉| 111/112 [04:31<00:02,  2.26s/it]\u001b[A\n",
      "loss 0.9407: 100%|██████████| 112/112 [04:31<00:00,  2.24s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [04:31<22:38, 271.75s/it]                \u001b[A\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1 - 0.9920245718955993\n",
      "saved checkpoint for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loss 1.0942:   0%|          | 0/112 [00:02<?, ?it/s]\u001b[A\n",
      "loss 1.0942:   1%|          | 1/112 [00:02<03:50,  2.08s/it]\u001b[A\n",
      "loss 1.0744:   1%|          | 1/112 [00:05<03:50,  2.08s/it]\u001b[A\n",
      "loss 1.0744:   2%|▏         | 2/112 [00:05<04:55,  2.69s/it]\u001b[A\n",
      "loss 1.0377:   2%|▏         | 2/112 [00:07<04:55,  2.69s/it]\u001b[A\n",
      "loss 1.0377:   3%|▎         | 3/112 [00:07<04:21,  2.40s/it]\u001b[A\n",
      "loss 0.9927:   3%|▎         | 3/112 [00:09<04:21,  2.40s/it]\u001b[A\n",
      "loss 0.9927:   4%|▎         | 4/112 [00:09<03:59,  2.21s/it]\u001b[A\n",
      "loss 0.9374:   4%|▎         | 4/112 [00:11<03:59,  2.21s/it]\u001b[A\n",
      "loss 0.9374:   4%|▍         | 5/112 [00:11<03:48,  2.14s/it]\u001b[A\n",
      "loss 0.9631:   4%|▍         | 5/112 [00:13<03:48,  2.14s/it]\u001b[A\n",
      "loss 0.9631:   5%|▌         | 6/112 [00:13<03:44,  2.11s/it]\u001b[A\n",
      "loss 0.9313:   5%|▌         | 6/112 [00:15<03:44,  2.11s/it]\u001b[A\n",
      "loss 0.9313:   6%|▋         | 7/112 [00:15<03:41,  2.11s/it]\u001b[A\n",
      "loss 0.9929:   6%|▋         | 7/112 [00:17<03:41,  2.11s/it]\u001b[A\n",
      "loss 0.9929:   7%|▋         | 8/112 [00:17<03:34,  2.06s/it]\u001b[A\n",
      "loss 0.9661:   7%|▋         | 8/112 [00:19<03:34,  2.06s/it]\u001b[A\n",
      "loss 0.9661:   8%|▊         | 9/112 [00:19<03:30,  2.04s/it]\u001b[A\n",
      "loss 0.9290:   8%|▊         | 9/112 [00:21<03:30,  2.04s/it]\u001b[A\n",
      "loss 0.9290:   9%|▉         | 10/112 [00:21<03:28,  2.04s/it]\u001b[A\n",
      "loss 1.0375:   9%|▉         | 10/112 [00:23<03:28,  2.04s/it]\u001b[A\n",
      "loss 1.0375:  10%|▉         | 11/112 [00:23<03:25,  2.04s/it]\u001b[A\n",
      "loss 0.9101:  10%|▉         | 11/112 [00:25<03:25,  2.04s/it]\u001b[A\n",
      "loss 0.9101:  11%|█         | 12/112 [00:25<03:27,  2.07s/it]\u001b[A\n",
      "loss 0.9064:  11%|█         | 12/112 [00:28<03:27,  2.07s/it]\u001b[A\n",
      "loss 0.9064:  12%|█▏        | 13/112 [00:28<03:37,  2.20s/it]\u001b[A\n",
      "loss 0.9401:  12%|█▏        | 13/112 [00:30<03:37,  2.20s/it]\u001b[A\n",
      "loss 0.9401:  12%|█▎        | 14/112 [00:30<03:45,  2.30s/it]\u001b[A\n",
      "loss 0.9710:  12%|█▎        | 14/112 [00:33<03:45,  2.30s/it]\u001b[A\n",
      "loss 0.9710:  13%|█▎        | 15/112 [00:33<03:51,  2.38s/it]\u001b[A\n",
      "loss 0.9567:  13%|█▎        | 15/112 [00:35<03:51,  2.38s/it]\u001b[A\n",
      "loss 0.9567:  14%|█▍        | 16/112 [00:35<03:47,  2.37s/it]\u001b[A\n",
      "loss 0.9897:  14%|█▍        | 16/112 [00:39<03:47,  2.37s/it]\u001b[A\n",
      "loss 0.9897:  15%|█▌        | 17/112 [00:39<04:26,  2.81s/it]\u001b[A\n",
      "loss 0.9492:  15%|█▌        | 17/112 [00:41<04:26,  2.81s/it]\u001b[A\n",
      "loss 0.9492:  16%|█▌        | 18/112 [00:41<04:18,  2.75s/it]\u001b[A\n",
      "loss 0.9791:  16%|█▌        | 18/112 [00:44<04:18,  2.75s/it]\u001b[A\n",
      "loss 0.9791:  17%|█▋        | 19/112 [00:44<04:24,  2.85s/it]\u001b[A\n",
      "loss 1.0402:  17%|█▋        | 19/112 [00:47<04:24,  2.85s/it]\u001b[A\n",
      "loss 1.0402:  18%|█▊        | 20/112 [00:47<04:19,  2.82s/it]\u001b[A\n",
      "loss 1.0036:  18%|█▊        | 20/112 [00:49<04:19,  2.82s/it]\u001b[A\n",
      "loss 1.0036:  19%|█▉        | 21/112 [00:49<03:53,  2.56s/it]\u001b[A\n",
      "loss 0.9084:  19%|█▉        | 21/112 [00:51<03:53,  2.56s/it]\u001b[A\n",
      "loss 0.9084:  20%|█▉        | 22/112 [00:51<03:38,  2.43s/it]\u001b[A\n",
      "loss 1.0088:  20%|█▉        | 22/112 [00:53<03:38,  2.43s/it]\u001b[A\n",
      "loss 1.0088:  21%|██        | 23/112 [00:53<03:24,  2.29s/it]\u001b[A\n",
      "loss 0.9145:  21%|██        | 23/112 [00:55<03:24,  2.29s/it]\u001b[A\n",
      "loss 0.9145:  21%|██▏       | 24/112 [00:55<03:12,  2.19s/it]\u001b[A\n",
      "loss 1.1626:  21%|██▏       | 24/112 [00:57<03:12,  2.19s/it]\u001b[A\n",
      "loss 1.1626:  22%|██▏       | 25/112 [00:57<03:04,  2.12s/it]\u001b[A\n",
      "loss 0.8497:  22%|██▏       | 25/112 [00:59<03:04,  2.12s/it]\u001b[A\n",
      "loss 0.8497:  23%|██▎       | 26/112 [00:59<02:58,  2.07s/it]\u001b[A\n",
      "loss 0.9727:  23%|██▎       | 26/112 [01:01<02:58,  2.07s/it]\u001b[A\n",
      "loss 0.9727:  24%|██▍       | 27/112 [01:01<02:55,  2.06s/it]\u001b[A\n",
      "loss 0.9658:  24%|██▍       | 27/112 [01:03<02:55,  2.06s/it]\u001b[A\n",
      "loss 0.9658:  25%|██▌       | 28/112 [01:03<02:56,  2.10s/it]\u001b[A\n",
      "loss 1.1330:  25%|██▌       | 28/112 [01:06<02:56,  2.10s/it]\u001b[A\n",
      "loss 1.1330:  26%|██▌       | 29/112 [01:06<02:58,  2.15s/it]\u001b[A\n",
      "loss 0.9213:  26%|██▌       | 29/112 [01:08<02:58,  2.15s/it]\u001b[A\n",
      "loss 0.9213:  27%|██▋       | 30/112 [01:08<02:56,  2.15s/it]\u001b[A\n",
      "loss 0.9481:  27%|██▋       | 30/112 [01:10<02:56,  2.15s/it]\u001b[A\n",
      "loss 0.9481:  28%|██▊       | 31/112 [01:10<02:50,  2.10s/it]\u001b[A\n",
      "loss 0.8812:  28%|██▊       | 31/112 [01:12<02:50,  2.10s/it]\u001b[A\n",
      "loss 0.8812:  29%|██▊       | 32/112 [01:12<02:44,  2.06s/it]\u001b[A\n",
      "loss 0.9755:  29%|██▊       | 32/112 [01:14<02:44,  2.06s/it]\u001b[A\n",
      "loss 0.9755:  29%|██▉       | 33/112 [01:14<02:39,  2.02s/it]\u001b[A\n",
      "loss 0.9372:  29%|██▉       | 33/112 [01:16<02:39,  2.02s/it]\u001b[A\n",
      "loss 0.9372:  30%|███       | 34/112 [01:16<02:35,  2.00s/it]\u001b[A\n",
      "loss 1.1041:  30%|███       | 34/112 [01:18<02:35,  2.00s/it]\u001b[A\n",
      "loss 1.1041:  31%|███▏      | 35/112 [01:18<02:33,  1.99s/it]\u001b[A\n",
      "loss 1.0354:  31%|███▏      | 35/112 [01:20<02:33,  1.99s/it]\u001b[A\n",
      "loss 1.0354:  32%|███▏      | 36/112 [01:20<02:30,  1.98s/it]\u001b[A\n",
      "loss 0.9597:  32%|███▏      | 36/112 [01:22<02:30,  1.98s/it]\u001b[A\n",
      "loss 0.9597:  33%|███▎      | 37/112 [01:22<02:30,  2.01s/it]\u001b[A\n",
      "loss 1.0212:  33%|███▎      | 37/112 [01:24<02:30,  2.01s/it]\u001b[A\n",
      "loss 1.0212:  34%|███▍      | 38/112 [01:24<02:42,  2.19s/it]\u001b[A\n",
      "loss 0.9574:  34%|███▍      | 38/112 [01:26<02:42,  2.19s/it]\u001b[A\n",
      "loss 0.9574:  35%|███▍      | 39/112 [01:26<02:40,  2.19s/it]\u001b[A\n",
      "loss 0.9589:  35%|███▍      | 39/112 [01:30<02:40,  2.19s/it]\u001b[A\n",
      "loss 0.9589:  36%|███▌      | 40/112 [01:30<03:05,  2.58s/it]\u001b[A\n",
      "loss 0.9951:  36%|███▌      | 40/112 [01:32<03:05,  2.58s/it]\u001b[A\n",
      "loss 0.9951:  37%|███▋      | 41/112 [01:32<02:55,  2.47s/it]\u001b[A\n",
      "loss 0.9395:  37%|███▋      | 41/112 [01:35<02:55,  2.47s/it]\u001b[A\n",
      "loss 0.9395:  38%|███▊      | 42/112 [01:35<03:01,  2.59s/it]\u001b[A\n",
      "loss 0.9731:  38%|███▊      | 42/112 [01:38<03:01,  2.59s/it]\u001b[A\n",
      "loss 0.9731:  38%|███▊      | 43/112 [01:38<02:59,  2.60s/it]\u001b[A\n",
      "loss 1.0479:  38%|███▊      | 43/112 [01:40<02:59,  2.60s/it]\u001b[A\n",
      "loss 1.0479:  39%|███▉      | 44/112 [01:40<02:43,  2.41s/it]\u001b[A\n",
      "loss 0.9303:  39%|███▉      | 44/112 [01:42<02:43,  2.41s/it]\u001b[A\n",
      "loss 0.9303:  40%|████      | 45/112 [01:42<02:32,  2.27s/it]\u001b[A\n",
      "loss 1.0855:  40%|████      | 45/112 [01:44<02:32,  2.27s/it]\u001b[A\n",
      "loss 1.0855:  41%|████      | 46/112 [01:44<02:25,  2.20s/it]\u001b[A\n",
      "loss 0.9913:  41%|████      | 46/112 [01:46<02:25,  2.20s/it]\u001b[A\n",
      "loss 0.9913:  42%|████▏     | 47/112 [01:46<02:20,  2.17s/it]\u001b[A\n",
      "loss 1.0375:  42%|████▏     | 47/112 [01:48<02:20,  2.17s/it]\u001b[A\n",
      "loss 1.0375:  43%|████▎     | 48/112 [01:48<02:19,  2.19s/it]\u001b[A\n",
      "loss 1.0457:  43%|████▎     | 48/112 [01:51<02:19,  2.19s/it]\u001b[A\n",
      "loss 1.0457:  44%|████▍     | 49/112 [01:51<02:40,  2.55s/it]\u001b[A\n",
      "loss 0.8828:  44%|████▍     | 49/112 [01:54<02:40,  2.55s/it]\u001b[A\n",
      "loss 0.8828:  45%|████▍     | 50/112 [01:54<02:42,  2.62s/it]\u001b[A\n",
      "loss 1.0119:  45%|████▍     | 50/112 [01:56<02:42,  2.62s/it]\u001b[A\n",
      "loss 1.0119:  46%|████▌     | 51/112 [01:56<02:30,  2.46s/it]\u001b[A\n",
      "loss 0.9131:  46%|████▌     | 51/112 [01:58<02:30,  2.46s/it]\u001b[A\n",
      "loss 0.9131:  46%|████▋     | 52/112 [01:58<02:24,  2.41s/it]\u001b[A\n",
      "loss 1.0489:  46%|████▋     | 52/112 [02:02<02:24,  2.41s/it]\u001b[A\n",
      "loss 1.0489:  47%|████▋     | 53/112 [02:02<02:39,  2.71s/it]\u001b[A\n",
      "loss 1.0553:  47%|████▋     | 53/112 [02:04<02:39,  2.71s/it]\u001b[A\n",
      "loss 1.0553:  48%|████▊     | 54/112 [02:04<02:26,  2.52s/it]\u001b[A\n",
      "loss 1.1607:  48%|████▊     | 54/112 [02:06<02:26,  2.52s/it]\u001b[A\n",
      "loss 1.1607:  49%|████▉     | 55/112 [02:06<02:16,  2.40s/it]\u001b[A\n",
      "loss 0.9677:  49%|████▉     | 55/112 [02:09<02:16,  2.40s/it]\u001b[A\n",
      "loss 0.9677:  50%|█████     | 56/112 [02:09<02:25,  2.60s/it]\u001b[A\n",
      "loss 0.9796:  50%|█████     | 56/112 [02:12<02:25,  2.60s/it]\u001b[A\n",
      "loss 0.9796:  51%|█████     | 57/112 [02:12<02:24,  2.62s/it]\u001b[A\n",
      "loss 0.8938:  51%|█████     | 57/112 [02:15<02:24,  2.62s/it]\u001b[A\n",
      "loss 0.8938:  52%|█████▏    | 58/112 [02:15<02:31,  2.81s/it]\u001b[A\n",
      "loss 1.0331:  52%|█████▏    | 58/112 [02:18<02:31,  2.81s/it]\u001b[A\n",
      "loss 1.0331:  53%|█████▎    | 59/112 [02:18<02:35,  2.93s/it]\u001b[A\n",
      "loss 1.0154:  53%|█████▎    | 59/112 [02:21<02:35,  2.93s/it]\u001b[A\n",
      "loss 1.0154:  54%|█████▎    | 60/112 [02:21<02:31,  2.91s/it]\u001b[A\n",
      "loss 1.0590:  54%|█████▎    | 60/112 [02:23<02:31,  2.91s/it]\u001b[A\n",
      "loss 1.0590:  54%|█████▍    | 61/112 [02:23<02:14,  2.63s/it]\u001b[A\n",
      "loss 0.9358:  54%|█████▍    | 61/112 [02:25<02:14,  2.63s/it]\u001b[A\n",
      "loss 0.9358:  55%|█████▌    | 62/112 [02:25<02:02,  2.44s/it]\u001b[A\n",
      "loss 1.0344:  55%|█████▌    | 62/112 [02:27<02:02,  2.44s/it]\u001b[A\n",
      "loss 1.0344:  56%|█████▋    | 63/112 [02:27<01:54,  2.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 1.0194:  56%|█████▋    | 63/112 [02:30<01:54,  2.33s/it]\u001b[A\n",
      "loss 1.0194:  57%|█████▋    | 64/112 [02:30<01:56,  2.42s/it]\u001b[A\n",
      "loss 1.0201:  57%|█████▋    | 64/112 [02:32<01:56,  2.42s/it]\u001b[A\n",
      "loss 1.0201:  58%|█████▊    | 65/112 [02:32<01:48,  2.31s/it]\u001b[A\n",
      "loss 0.9923:  58%|█████▊    | 65/112 [02:34<01:48,  2.31s/it]\u001b[A\n",
      "loss 0.9923:  59%|█████▉    | 66/112 [02:34<01:41,  2.22s/it]\u001b[A\n",
      "loss 0.9876:  59%|█████▉    | 66/112 [02:36<01:41,  2.22s/it]\u001b[A\n",
      "loss 0.9876:  60%|█████▉    | 67/112 [02:36<01:36,  2.15s/it]\u001b[A\n",
      "loss 0.9586:  60%|█████▉    | 67/112 [02:38<01:36,  2.15s/it]\u001b[A\n",
      "loss 0.9586:  61%|██████    | 68/112 [02:38<01:40,  2.29s/it]\u001b[A\n",
      "loss 0.9873:  61%|██████    | 68/112 [02:42<01:40,  2.29s/it]\u001b[A\n",
      "loss 0.9873:  62%|██████▏   | 69/112 [02:42<01:51,  2.59s/it]\u001b[A\n",
      "loss 1.0947:  62%|██████▏   | 69/112 [02:44<01:51,  2.59s/it]\u001b[A\n",
      "loss 1.0947:  62%|██████▎   | 70/112 [02:44<01:41,  2.41s/it]\u001b[A\n",
      "loss 1.0347:  62%|██████▎   | 70/112 [02:46<01:41,  2.41s/it]\u001b[A\n",
      "loss 1.0347:  63%|██████▎   | 71/112 [02:46<01:35,  2.33s/it]\u001b[A\n",
      "loss 0.8578:  63%|██████▎   | 71/112 [02:49<01:35,  2.33s/it]\u001b[A\n",
      "loss 0.8578:  64%|██████▍   | 72/112 [02:49<01:41,  2.54s/it]\u001b[A\n",
      "loss 0.9794:  64%|██████▍   | 72/112 [02:51<01:41,  2.54s/it]\u001b[A\n",
      "loss 0.9794:  65%|██████▌   | 73/112 [02:51<01:33,  2.39s/it]\u001b[A\n",
      "loss 1.0526:  65%|██████▌   | 73/112 [02:53<01:33,  2.39s/it]\u001b[A\n",
      "loss 1.0526:  66%|██████▌   | 74/112 [02:53<01:25,  2.26s/it]\u001b[A\n",
      "loss 0.9409:  66%|██████▌   | 74/112 [02:55<01:25,  2.26s/it]\u001b[A\n",
      "loss 0.9409:  67%|██████▋   | 75/112 [02:55<01:20,  2.17s/it]\u001b[A\n",
      "loss 1.1229:  67%|██████▋   | 75/112 [02:58<01:20,  2.17s/it]\u001b[A\n",
      "loss 1.1229:  68%|██████▊   | 76/112 [02:58<01:24,  2.34s/it]\u001b[A\n",
      "loss 1.1212:  68%|██████▊   | 76/112 [03:00<01:24,  2.34s/it]\u001b[A\n",
      "loss 1.1212:  69%|██████▉   | 77/112 [03:00<01:25,  2.43s/it]\u001b[A\n",
      "loss 1.0001:  69%|██████▉   | 77/112 [03:02<01:25,  2.43s/it]\u001b[A\n",
      "loss 1.0001:  70%|██████▉   | 78/112 [03:02<01:17,  2.28s/it]\u001b[A\n",
      "loss 1.1105:  70%|██████▉   | 78/112 [03:04<01:17,  2.28s/it]\u001b[A\n",
      "loss 1.1105:  71%|███████   | 79/112 [03:04<01:11,  2.18s/it]\u001b[A\n",
      "loss 0.9817:  71%|███████   | 79/112 [03:06<01:11,  2.18s/it]\u001b[A\n",
      "loss 0.9817:  71%|███████▏  | 80/112 [03:06<01:07,  2.11s/it]\u001b[A\n",
      "loss 0.9281:  71%|███████▏  | 80/112 [03:08<01:07,  2.11s/it]\u001b[A\n",
      "loss 0.9281:  72%|███████▏  | 81/112 [03:08<01:04,  2.07s/it]\u001b[A\n",
      "loss 0.9168:  72%|███████▏  | 81/112 [03:10<01:04,  2.07s/it]\u001b[A\n",
      "loss 0.9168:  73%|███████▎  | 82/112 [03:10<01:00,  2.03s/it]\u001b[A\n",
      "loss 0.9866:  73%|███████▎  | 82/112 [03:12<01:00,  2.03s/it]\u001b[A\n",
      "loss 0.9866:  74%|███████▍  | 83/112 [03:12<00:58,  2.01s/it]\u001b[A\n",
      "loss 1.1132:  74%|███████▍  | 83/112 [03:14<00:58,  2.01s/it]\u001b[A\n",
      "loss 1.1132:  75%|███████▌  | 84/112 [03:14<00:55,  1.99s/it]\u001b[A\n",
      "loss 0.9725:  75%|███████▌  | 84/112 [03:16<00:55,  1.99s/it]\u001b[A\n",
      "loss 0.9725:  76%|███████▌  | 85/112 [03:16<00:53,  1.97s/it]\u001b[A\n",
      "loss 0.9734:  76%|███████▌  | 85/112 [03:18<00:53,  1.97s/it]\u001b[A\n",
      "loss 0.9734:  77%|███████▋  | 86/112 [03:18<00:51,  1.96s/it]\u001b[A\n",
      "loss 0.9953:  77%|███████▋  | 86/112 [03:20<00:51,  1.96s/it]\u001b[A\n",
      "loss 0.9953:  78%|███████▊  | 87/112 [03:20<00:49,  1.96s/it]\u001b[A\n",
      "loss 1.0454:  78%|███████▊  | 87/112 [03:22<00:49,  1.96s/it]\u001b[A\n",
      "loss 1.0454:  79%|███████▊  | 88/112 [03:22<00:46,  1.95s/it]\u001b[A\n",
      "loss 1.0364:  79%|███████▊  | 88/112 [03:24<00:46,  1.95s/it]\u001b[A\n",
      "loss 1.0364:  79%|███████▉  | 89/112 [03:24<00:44,  1.95s/it]\u001b[A\n",
      "loss 0.8963:  79%|███████▉  | 89/112 [03:26<00:44,  1.95s/it]\u001b[A\n",
      "loss 0.8963:  80%|████████  | 90/112 [03:26<00:42,  1.95s/it]\u001b[A\n",
      "loss 0.9724:  80%|████████  | 90/112 [03:28<00:42,  1.95s/it]\u001b[A\n",
      "loss 0.9724:  81%|████████▏ | 91/112 [03:28<00:41,  1.97s/it]\u001b[A\n",
      "loss 1.0190:  81%|████████▏ | 91/112 [03:30<00:41,  1.97s/it]\u001b[A\n",
      "loss 1.0190:  82%|████████▏ | 92/112 [03:30<00:39,  1.96s/it]\u001b[A\n",
      "loss 0.9222:  82%|████████▏ | 92/112 [03:32<00:39,  1.96s/it]\u001b[A\n",
      "loss 0.9222:  83%|████████▎ | 93/112 [03:32<00:37,  1.98s/it]\u001b[A\n",
      "loss 0.9829:  83%|████████▎ | 93/112 [03:34<00:37,  1.98s/it]\u001b[A\n",
      "loss 0.9829:  84%|████████▍ | 94/112 [03:34<00:35,  1.99s/it]\u001b[A\n",
      "loss 0.9655:  84%|████████▍ | 94/112 [03:36<00:35,  1.99s/it]\u001b[A\n",
      "loss 0.9655:  85%|████████▍ | 95/112 [03:36<00:35,  2.08s/it]\u001b[A\n",
      "loss 1.0453:  85%|████████▍ | 95/112 [03:38<00:35,  2.08s/it]\u001b[A\n",
      "loss 1.0453:  86%|████████▌ | 96/112 [03:38<00:34,  2.16s/it]\u001b[A\n",
      "loss 1.1245:  86%|████████▌ | 96/112 [03:41<00:34,  2.16s/it]\u001b[A\n",
      "loss 1.1245:  87%|████████▋ | 97/112 [03:41<00:36,  2.45s/it]\u001b[A\n",
      "loss 1.0897:  87%|████████▋ | 97/112 [03:44<00:36,  2.45s/it]\u001b[A\n",
      "loss 1.0897:  88%|████████▊ | 98/112 [03:44<00:33,  2.40s/it]\u001b[A\n",
      "loss 1.0289:  88%|████████▊ | 98/112 [03:46<00:33,  2.40s/it]\u001b[A\n",
      "loss 1.0289:  88%|████████▊ | 99/112 [03:46<00:31,  2.43s/it]\u001b[A\n",
      "loss 0.8867:  88%|████████▊ | 99/112 [03:49<00:31,  2.43s/it]\u001b[A\n",
      "loss 0.8867:  89%|████████▉ | 100/112 [03:49<00:30,  2.57s/it]\u001b[A\n",
      "loss 1.0240:  89%|████████▉ | 100/112 [03:52<00:30,  2.57s/it]\u001b[A\n",
      "loss 1.0240:  90%|█████████ | 101/112 [03:52<00:28,  2.61s/it]\u001b[A\n",
      "loss 1.0535:  90%|█████████ | 101/112 [03:54<00:28,  2.61s/it]\u001b[A\n",
      "loss 1.0535:  91%|█████████ | 102/112 [03:54<00:25,  2.55s/it]\u001b[A\n",
      "loss 1.0509:  91%|█████████ | 102/112 [03:56<00:25,  2.55s/it]\u001b[A\n",
      "loss 1.0509:  92%|█████████▏| 103/112 [03:56<00:21,  2.38s/it]\u001b[A\n",
      "loss 0.9722:  92%|█████████▏| 103/112 [03:58<00:21,  2.38s/it]\u001b[A\n",
      "loss 0.9722:  93%|█████████▎| 104/112 [03:58<00:18,  2.26s/it]\u001b[A\n",
      "loss 0.9695:  93%|█████████▎| 104/112 [04:00<00:18,  2.26s/it]\u001b[A\n",
      "loss 0.9695:  94%|█████████▍| 105/112 [04:00<00:15,  2.17s/it]\u001b[A\n",
      "loss 1.0821:  94%|█████████▍| 105/112 [04:02<00:15,  2.17s/it]\u001b[A\n",
      "loss 1.0821:  95%|█████████▍| 106/112 [04:02<00:12,  2.11s/it]\u001b[A\n",
      "loss 1.0155:  95%|█████████▍| 106/112 [04:04<00:12,  2.11s/it]\u001b[A\n",
      "loss 1.0155:  96%|█████████▌| 107/112 [04:04<00:10,  2.07s/it]\u001b[A\n",
      "loss 0.9990:  96%|█████████▌| 107/112 [04:06<00:10,  2.07s/it]\u001b[A\n",
      "loss 0.9990:  96%|█████████▋| 108/112 [04:06<00:08,  2.03s/it]\u001b[A\n",
      "loss 0.9471:  96%|█████████▋| 108/112 [04:08<00:08,  2.03s/it]\u001b[A\n",
      "loss 0.9471:  97%|█████████▋| 109/112 [04:08<00:05,  2.00s/it]\u001b[A\n",
      "loss 0.9182:  97%|█████████▋| 109/112 [04:10<00:05,  2.00s/it]\u001b[A\n",
      "loss 0.9182:  98%|█████████▊| 110/112 [04:10<00:03,  1.98s/it]\u001b[A\n",
      "loss 0.9147:  98%|█████████▊| 110/112 [04:12<00:03,  1.98s/it]\u001b[A\n",
      "loss 0.9147:  99%|█████████▉| 111/112 [04:12<00:01,  1.97s/it]\u001b[A\n",
      "loss 0.9243:  99%|█████████▉| 111/112 [04:13<00:01,  1.97s/it]\u001b[A\n",
      "loss 0.9243: 100%|██████████| 112/112 [04:13<00:00,  1.67s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [08:45<17:23, 260.91s/it]                \u001b[A\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2 - 0.9941827791929245\n",
      "saved checkpoint for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loss 0.9525:   0%|          | 0/112 [00:01<?, ?it/s]\u001b[A\n",
      "loss 0.9525:   1%|          | 1/112 [00:01<03:36,  1.95s/it]\u001b[A\n",
      "loss 0.9052:   1%|          | 1/112 [00:03<03:36,  1.95s/it]\u001b[A\n",
      "loss 0.9052:   2%|▏         | 2/112 [00:03<03:33,  1.94s/it]\u001b[A\n",
      "loss 1.0445:   2%|▏         | 2/112 [00:05<03:33,  1.94s/it]\u001b[A\n",
      "loss 1.0445:   3%|▎         | 3/112 [00:05<03:31,  1.94s/it]\u001b[A\n",
      "loss 0.9044:   3%|▎         | 3/112 [00:07<03:31,  1.94s/it]\u001b[A\n",
      "loss 0.9044:   4%|▎         | 4/112 [00:07<03:29,  1.94s/it]\u001b[A\n",
      "loss 0.9686:   4%|▎         | 4/112 [00:09<03:29,  1.94s/it]\u001b[A\n",
      "loss 0.9686:   4%|▍         | 5/112 [00:09<03:28,  1.95s/it]\u001b[A\n",
      "loss 1.0388:   4%|▍         | 5/112 [00:11<03:28,  1.95s/it]\u001b[A\n",
      "loss 1.0388:   5%|▌         | 6/112 [00:11<03:26,  1.95s/it]\u001b[A\n",
      "loss 0.9613:   5%|▌         | 6/112 [00:13<03:26,  1.95s/it]\u001b[A\n",
      "loss 0.9613:   6%|▋         | 7/112 [00:13<03:23,  1.94s/it]\u001b[A\n",
      "loss 1.1376:   6%|▋         | 7/112 [00:15<03:23,  1.94s/it]\u001b[A\n",
      "loss 1.1376:   7%|▋         | 8/112 [00:15<03:24,  1.96s/it]\u001b[A\n",
      "loss 1.0091:   7%|▋         | 8/112 [00:17<03:24,  1.96s/it]\u001b[A\n",
      "loss 1.0091:   8%|▊         | 9/112 [00:17<03:24,  1.99s/it]\u001b[A\n",
      "loss 1.0497:   8%|▊         | 9/112 [00:19<03:24,  1.99s/it]\u001b[A\n",
      "loss 1.0497:   9%|▉         | 10/112 [00:19<03:31,  2.08s/it]\u001b[A\n",
      "loss 1.0388:   9%|▉         | 10/112 [00:22<03:31,  2.08s/it]\u001b[A\n",
      "loss 1.0388:  10%|▉         | 11/112 [00:22<03:40,  2.18s/it]\u001b[A\n",
      "loss 1.0576:  10%|▉         | 11/112 [00:25<03:40,  2.18s/it]\u001b[A\n",
      "loss 1.0576:  11%|█         | 12/112 [00:25<04:12,  2.52s/it]\u001b[A\n",
      "loss 0.9484:  11%|█         | 12/112 [00:29<04:12,  2.52s/it]\u001b[A\n",
      "loss 0.9484:  12%|█▏        | 13/112 [00:29<04:42,  2.85s/it]\u001b[A\n",
      "loss 0.8926:  12%|█▏        | 13/112 [00:31<04:42,  2.85s/it]\u001b[A\n",
      "loss 0.8926:  12%|█▎        | 14/112 [00:31<04:15,  2.60s/it]\u001b[A\n",
      "loss 0.9767:  12%|█▎        | 14/112 [00:33<04:15,  2.60s/it]\u001b[A\n",
      "loss 0.9767:  13%|█▎        | 15/112 [00:33<03:54,  2.42s/it]\u001b[A\n",
      "loss 1.0033:  13%|█▎        | 15/112 [00:35<03:54,  2.42s/it]\u001b[A\n",
      "loss 1.0033:  14%|█▍        | 16/112 [00:35<03:45,  2.35s/it]\u001b[A\n",
      "loss 0.9048:  14%|█▍        | 16/112 [00:37<03:45,  2.35s/it]\u001b[A\n",
      "loss 0.9048:  15%|█▌        | 17/112 [00:37<03:42,  2.34s/it]\u001b[A\n",
      "loss 0.9919:  15%|█▌        | 17/112 [00:40<03:42,  2.34s/it]\u001b[A\n",
      "loss 0.9919:  16%|█▌        | 18/112 [00:40<04:02,  2.58s/it]\u001b[A\n",
      "loss 0.9637:  16%|█▌        | 18/112 [00:42<04:02,  2.58s/it]\u001b[A\n",
      "loss 0.9637:  17%|█▋        | 19/112 [00:42<03:42,  2.40s/it]\u001b[A\n",
      "loss 0.9912:  17%|█▋        | 19/112 [00:44<03:42,  2.40s/it]\u001b[A\n",
      "loss 0.9912:  18%|█▊        | 20/112 [00:44<03:28,  2.27s/it]\u001b[A\n",
      "loss 0.9802:  18%|█▊        | 20/112 [00:46<03:28,  2.27s/it]\u001b[A\n",
      "loss 0.9802:  19%|█▉        | 21/112 [00:46<03:18,  2.18s/it]\u001b[A\n",
      "loss 1.0332:  19%|█▉        | 21/112 [00:48<03:18,  2.18s/it]\u001b[A\n",
      "loss 1.0332:  20%|█▉        | 22/112 [00:48<03:11,  2.12s/it]\u001b[A\n",
      "loss 0.9113:  20%|█▉        | 22/112 [00:50<03:11,  2.12s/it]\u001b[A\n",
      "loss 0.9113:  21%|██        | 23/112 [00:50<03:04,  2.08s/it]\u001b[A\n",
      "loss 0.9326:  21%|██        | 23/112 [00:52<03:04,  2.08s/it]\u001b[A\n",
      "loss 0.9326:  21%|██▏       | 24/112 [00:52<03:00,  2.05s/it]\u001b[A\n",
      "loss 0.9934:  21%|██▏       | 24/112 [00:54<03:00,  2.05s/it]\u001b[A\n",
      "loss 0.9934:  22%|██▏       | 25/112 [00:54<02:55,  2.02s/it]\u001b[A\n",
      "loss 0.8798:  22%|██▏       | 25/112 [00:56<02:55,  2.02s/it]\u001b[A\n",
      "loss 0.8798:  23%|██▎       | 26/112 [00:56<02:51,  1.99s/it]\u001b[A\n",
      "loss 1.0040:  23%|██▎       | 26/112 [00:58<02:51,  1.99s/it]\u001b[A\n",
      "loss 1.0040:  24%|██▍       | 27/112 [00:58<02:47,  1.98s/it]\u001b[A\n",
      "loss 1.1112:  24%|██▍       | 27/112 [01:00<02:47,  1.98s/it]\u001b[A\n",
      "loss 1.1112:  25%|██▌       | 28/112 [01:00<02:45,  1.97s/it]\u001b[A\n",
      "loss 0.9635:  25%|██▌       | 28/112 [01:02<02:45,  1.97s/it]\u001b[A\n",
      "loss 0.9635:  26%|██▌       | 29/112 [01:02<02:42,  1.96s/it]\u001b[A\n",
      "loss 0.9000:  26%|██▌       | 29/112 [01:04<02:42,  1.96s/it]\u001b[A\n",
      "loss 0.9000:  27%|██▋       | 30/112 [01:04<02:40,  1.96s/it]\u001b[A\n",
      "loss 1.0582:  27%|██▋       | 30/112 [01:06<02:40,  1.96s/it]\u001b[A\n",
      "loss 1.0582:  28%|██▊       | 31/112 [01:06<02:39,  1.97s/it]\u001b[A\n",
      "loss 0.8552:  28%|██▊       | 31/112 [01:08<02:39,  1.97s/it]\u001b[A\n",
      "loss 0.8552:  29%|██▊       | 32/112 [01:08<02:38,  1.98s/it]\u001b[A\n",
      "loss 0.9170:  29%|██▊       | 32/112 [01:10<02:38,  1.98s/it]\u001b[A\n",
      "loss 0.9170:  29%|██▉       | 33/112 [01:10<02:38,  2.00s/it]\u001b[A\n",
      "loss 1.0187:  29%|██▉       | 33/112 [01:12<02:38,  2.00s/it]\u001b[A\n",
      "loss 1.0187:  30%|███       | 34/112 [01:12<02:35,  2.00s/it]\u001b[A\n",
      "loss 0.9285:  30%|███       | 34/112 [01:14<02:35,  2.00s/it]\u001b[A\n",
      "loss 0.9285:  31%|███▏      | 35/112 [01:14<02:32,  1.98s/it]\u001b[A\n",
      "loss 0.9931:  31%|███▏      | 35/112 [01:16<02:32,  1.98s/it]\u001b[A\n",
      "loss 0.9931:  32%|███▏      | 36/112 [01:16<02:30,  1.98s/it]\u001b[A\n",
      "loss 0.9754:  32%|███▏      | 36/112 [01:18<02:30,  1.98s/it]\u001b[A\n",
      "loss 0.9754:  33%|███▎      | 37/112 [01:18<02:37,  2.10s/it]\u001b[A\n",
      "loss 0.9316:  33%|███▎      | 37/112 [01:20<02:37,  2.10s/it]\u001b[A\n",
      "loss 0.9316:  34%|███▍      | 38/112 [01:20<02:37,  2.13s/it]\u001b[A\n",
      "loss 0.9232:  34%|███▍      | 38/112 [01:23<02:37,  2.13s/it]\u001b[A\n",
      "loss 0.9232:  35%|███▍      | 39/112 [01:23<02:42,  2.22s/it]\u001b[A\n",
      "loss 0.9523:  35%|███▍      | 39/112 [01:25<02:42,  2.22s/it]\u001b[A\n",
      "loss 0.9523:  36%|███▌      | 40/112 [01:25<02:42,  2.25s/it]\u001b[A\n",
      "loss 1.0710:  36%|███▌      | 40/112 [01:27<02:42,  2.25s/it]\u001b[A\n",
      "loss 1.0710:  37%|███▋      | 41/112 [01:27<02:37,  2.22s/it]\u001b[A\n",
      "loss 0.9458:  37%|███▋      | 41/112 [01:30<02:37,  2.22s/it]\u001b[A\n",
      "loss 0.9458:  38%|███▊      | 42/112 [01:30<02:35,  2.22s/it]\u001b[A\n",
      "loss 1.1940:  38%|███▊      | 42/112 [01:32<02:35,  2.22s/it]\u001b[A\n",
      "loss 1.1940:  38%|███▊      | 43/112 [01:32<02:33,  2.22s/it]\u001b[A\n",
      "loss 1.0358:  38%|███▊      | 43/112 [01:34<02:33,  2.22s/it]\u001b[A\n",
      "loss 1.0358:  39%|███▉      | 44/112 [01:34<02:32,  2.24s/it]\u001b[A\n",
      "loss 1.0182:  39%|███▉      | 44/112 [01:36<02:32,  2.24s/it]\u001b[A\n",
      "loss 1.0182:  40%|████      | 45/112 [01:36<02:27,  2.20s/it]\u001b[A\n",
      "loss 1.0122:  40%|████      | 45/112 [01:39<02:27,  2.20s/it]\u001b[A\n",
      "loss 1.0122:  41%|████      | 46/112 [01:39<02:30,  2.28s/it]\u001b[A\n",
      "loss 0.9965:  41%|████      | 46/112 [01:41<02:30,  2.28s/it]\u001b[A\n",
      "loss 0.9965:  42%|████▏     | 47/112 [01:41<02:26,  2.25s/it]\u001b[A\n",
      "loss 0.9089:  42%|████▏     | 47/112 [01:43<02:26,  2.25s/it]\u001b[A\n",
      "loss 0.9089:  43%|████▎     | 48/112 [01:43<02:19,  2.18s/it]\u001b[A\n",
      "loss 1.0377:  43%|████▎     | 48/112 [01:45<02:19,  2.18s/it]\u001b[A\n",
      "loss 1.0377:  44%|████▍     | 49/112 [01:45<02:21,  2.24s/it]\u001b[A\n",
      "loss 1.0085:  44%|████▍     | 49/112 [01:48<02:21,  2.24s/it]\u001b[A\n",
      "loss 1.0085:  45%|████▍     | 50/112 [01:48<02:24,  2.33s/it]\u001b[A\n",
      "loss 1.0531:  45%|████▍     | 50/112 [01:50<02:24,  2.33s/it]\u001b[A\n",
      "loss 1.0531:  46%|████▌     | 51/112 [01:50<02:27,  2.43s/it]\u001b[A\n",
      "loss 1.0338:  46%|████▌     | 51/112 [01:53<02:27,  2.43s/it]\u001b[A\n",
      "loss 1.0338:  46%|████▋     | 52/112 [01:53<02:23,  2.40s/it]\u001b[A\n",
      "loss 0.9954:  46%|████▋     | 52/112 [01:55<02:23,  2.40s/it]\u001b[A\n",
      "loss 0.9954:  47%|████▋     | 53/112 [01:55<02:23,  2.43s/it]\u001b[A\n",
      "loss 1.0130:  47%|████▋     | 53/112 [01:58<02:23,  2.43s/it]\u001b[A\n",
      "loss 1.0130:  48%|████▊     | 54/112 [01:58<02:20,  2.42s/it]\u001b[A\n",
      "loss 0.9698:  48%|████▊     | 54/112 [02:00<02:20,  2.42s/it]\u001b[A\n",
      "loss 0.9698:  49%|████▉     | 55/112 [02:00<02:11,  2.31s/it]\u001b[A\n",
      "loss 0.9505:  49%|████▉     | 55/112 [02:02<02:11,  2.31s/it]\u001b[A\n",
      "loss 0.9505:  50%|█████     | 56/112 [02:02<02:03,  2.20s/it]\u001b[A\n",
      "loss 1.2203:  50%|█████     | 56/112 [02:04<02:03,  2.20s/it]\u001b[A\n",
      "loss 1.2203:  51%|█████     | 57/112 [02:04<01:56,  2.12s/it]\u001b[A\n",
      "loss 1.0932:  51%|█████     | 57/112 [02:06<01:56,  2.12s/it]\u001b[A\n",
      "loss 1.0932:  52%|█████▏    | 58/112 [02:06<01:51,  2.06s/it]\u001b[A\n",
      "loss 1.0849:  52%|█████▏    | 58/112 [02:07<01:51,  2.06s/it]\u001b[A\n",
      "loss 1.0849:  53%|█████▎    | 59/112 [02:07<01:47,  2.02s/it]\u001b[A\n",
      "loss 1.0060:  53%|█████▎    | 59/112 [02:09<01:47,  2.02s/it]\u001b[A\n",
      "loss 1.0060:  54%|█████▎    | 60/112 [02:09<01:43,  2.00s/it]\u001b[A\n",
      "loss 1.0206:  54%|█████▎    | 60/112 [02:11<01:43,  2.00s/it]\u001b[A\n",
      "loss 1.0206:  54%|█████▍    | 61/112 [02:11<01:41,  1.98s/it]\u001b[A\n",
      "loss 0.9769:  54%|█████▍    | 61/112 [02:13<01:41,  1.98s/it]\u001b[A\n",
      "loss 0.9769:  55%|█████▌    | 62/112 [02:13<01:38,  1.97s/it]\u001b[A\n",
      "loss 0.9451:  55%|█████▌    | 62/112 [02:15<01:38,  1.97s/it]\u001b[A\n",
      "loss 0.9451:  56%|█████▋    | 63/112 [02:15<01:37,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.9062:  56%|█████▋    | 63/112 [02:17<01:37,  1.99s/it]\u001b[A\n",
      "loss 0.9062:  57%|█████▋    | 64/112 [02:17<01:36,  2.00s/it]\u001b[A\n",
      "loss 1.0714:  57%|█████▋    | 64/112 [02:19<01:36,  2.00s/it]\u001b[A\n",
      "loss 1.0714:  58%|█████▊    | 65/112 [02:19<01:34,  2.02s/it]\u001b[A\n",
      "loss 0.9309:  58%|█████▊    | 65/112 [02:21<01:34,  2.02s/it]\u001b[A\n",
      "loss 0.9309:  59%|█████▉    | 66/112 [02:21<01:32,  2.00s/it]\u001b[A\n",
      "loss 0.9709:  59%|█████▉    | 66/112 [02:23<01:32,  2.00s/it]\u001b[A\n",
      "loss 0.9709:  60%|█████▉    | 67/112 [02:23<01:30,  2.00s/it]\u001b[A\n",
      "loss 0.9243:  60%|█████▉    | 67/112 [02:25<01:30,  2.00s/it]\u001b[A\n",
      "loss 0.9243:  61%|██████    | 68/112 [02:25<01:27,  1.99s/it]\u001b[A\n",
      "loss 0.9347:  61%|██████    | 68/112 [02:27<01:27,  1.99s/it]\u001b[A\n",
      "loss 0.9347:  62%|██████▏   | 69/112 [02:27<01:24,  1.97s/it]\u001b[A\n",
      "loss 0.9726:  62%|██████▏   | 69/112 [02:29<01:24,  1.97s/it]\u001b[A\n",
      "loss 0.9726:  62%|██████▎   | 70/112 [02:29<01:22,  1.96s/it]\u001b[A\n",
      "loss 1.1385:  62%|██████▎   | 70/112 [02:31<01:22,  1.96s/it]\u001b[A\n",
      "loss 1.1385:  63%|██████▎   | 71/112 [02:31<01:20,  1.95s/it]\u001b[A\n",
      "loss 0.9381:  63%|██████▎   | 71/112 [02:33<01:20,  1.95s/it]\u001b[A\n",
      "loss 0.9381:  64%|██████▍   | 72/112 [02:33<01:18,  1.95s/it]\u001b[A\n",
      "loss 0.9364:  64%|██████▍   | 72/112 [02:35<01:18,  1.95s/it]\u001b[A\n",
      "loss 0.9364:  65%|██████▌   | 73/112 [02:35<01:16,  1.95s/it]\u001b[A\n",
      "loss 1.0234:  65%|██████▌   | 73/112 [02:37<01:16,  1.95s/it]\u001b[A\n",
      "loss 1.0234:  66%|██████▌   | 74/112 [02:37<01:14,  1.95s/it]\u001b[A\n",
      "loss 0.9014:  66%|██████▌   | 74/112 [02:39<01:14,  1.95s/it]\u001b[A\n",
      "loss 0.9014:  67%|██████▋   | 75/112 [02:39<01:13,  2.00s/it]\u001b[A\n",
      "loss 0.9993:  67%|██████▋   | 75/112 [02:41<01:13,  2.00s/it]\u001b[A\n",
      "loss 0.9993:  68%|██████▊   | 76/112 [02:41<01:13,  2.05s/it]\u001b[A\n",
      "loss 0.9568:  68%|██████▊   | 76/112 [02:43<01:13,  2.05s/it]\u001b[A\n",
      "loss 0.9568:  69%|██████▉   | 77/112 [02:43<01:10,  2.01s/it]\u001b[A\n",
      "loss 0.8732:  69%|██████▉   | 77/112 [02:45<01:10,  2.01s/it]\u001b[A\n",
      "loss 0.8732:  70%|██████▉   | 78/112 [02:45<01:07,  1.99s/it]\u001b[A\n",
      "loss 1.0238:  70%|██████▉   | 78/112 [02:47<01:07,  1.99s/it]\u001b[A\n",
      "loss 1.0238:  71%|███████   | 79/112 [02:47<01:05,  1.98s/it]\u001b[A\n",
      "loss 1.0572:  71%|███████   | 79/112 [02:49<01:05,  1.98s/it]\u001b[A\n",
      "loss 1.0572:  71%|███████▏  | 80/112 [02:49<01:03,  1.98s/it]\u001b[A\n",
      "loss 1.0281:  71%|███████▏  | 80/112 [02:51<01:03,  1.98s/it]\u001b[A\n",
      "loss 1.0281:  72%|███████▏  | 81/112 [02:51<01:01,  1.97s/it]\u001b[A\n",
      "loss 0.9134:  72%|███████▏  | 81/112 [02:53<01:01,  1.97s/it]\u001b[A\n",
      "loss 0.9134:  73%|███████▎  | 82/112 [02:53<00:58,  1.96s/it]\u001b[A\n",
      "loss 1.0941:  73%|███████▎  | 82/112 [02:55<00:58,  1.96s/it]\u001b[A\n",
      "loss 1.0941:  74%|███████▍  | 83/112 [02:55<00:57,  1.98s/it]\u001b[A\n",
      "loss 1.0061:  74%|███████▍  | 83/112 [02:58<00:57,  1.98s/it]\u001b[A\n",
      "loss 1.0061:  75%|███████▌  | 84/112 [02:58<01:03,  2.28s/it]\u001b[A\n",
      "loss 1.0508:  75%|███████▌  | 84/112 [03:00<01:03,  2.28s/it]\u001b[A\n",
      "loss 1.0508:  76%|███████▌  | 85/112 [03:00<00:58,  2.18s/it]\u001b[A\n",
      "loss 0.9821:  76%|███████▌  | 85/112 [03:02<00:58,  2.18s/it]\u001b[A\n",
      "loss 0.9821:  77%|███████▋  | 86/112 [03:02<00:55,  2.12s/it]\u001b[A\n",
      "loss 0.9136:  77%|███████▋  | 86/112 [03:04<00:55,  2.12s/it]\u001b[A\n",
      "loss 0.9136:  78%|███████▊  | 87/112 [03:04<00:52,  2.10s/it]\u001b[A\n",
      "loss 0.8514:  78%|███████▊  | 87/112 [03:06<00:52,  2.10s/it]\u001b[A\n",
      "loss 0.8514:  79%|███████▊  | 88/112 [03:06<00:49,  2.06s/it]\u001b[A\n",
      "loss 1.0582:  79%|███████▊  | 88/112 [03:08<00:49,  2.06s/it]\u001b[A\n",
      "loss 1.0582:  79%|███████▉  | 89/112 [03:08<00:46,  2.03s/it]\u001b[A\n",
      "loss 1.0741:  79%|███████▉  | 89/112 [03:10<00:46,  2.03s/it]\u001b[A\n",
      "loss 1.0741:  80%|████████  | 90/112 [03:10<00:44,  2.01s/it]\u001b[A\n",
      "loss 1.0228:  80%|████████  | 90/112 [03:12<00:44,  2.01s/it]\u001b[A\n",
      "loss 1.0228:  81%|████████▏ | 91/112 [03:12<00:41,  1.99s/it]\u001b[A\n",
      "loss 0.9208:  81%|████████▏ | 91/112 [03:14<00:41,  1.99s/it]\u001b[A\n",
      "loss 0.9208:  82%|████████▏ | 92/112 [03:14<00:39,  1.98s/it]\u001b[A\n",
      "loss 0.9532:  82%|████████▏ | 92/112 [03:16<00:39,  1.98s/it]\u001b[A\n",
      "loss 0.9532:  83%|████████▎ | 93/112 [03:16<00:37,  1.97s/it]\u001b[A\n",
      "loss 0.9615:  83%|████████▎ | 93/112 [03:18<00:37,  1.97s/it]\u001b[A\n",
      "loss 0.9615:  84%|████████▍ | 94/112 [03:18<00:35,  1.97s/it]\u001b[A\n",
      "loss 1.0086:  84%|████████▍ | 94/112 [03:20<00:35,  1.97s/it]\u001b[A\n",
      "loss 1.0086:  85%|████████▍ | 95/112 [03:20<00:33,  1.98s/it]\u001b[A\n",
      "loss 0.9509:  85%|████████▍ | 95/112 [03:22<00:33,  1.98s/it]\u001b[A\n",
      "loss 0.9509:  86%|████████▌ | 96/112 [03:22<00:31,  1.97s/it]\u001b[A\n",
      "loss 0.9679:  86%|████████▌ | 96/112 [03:24<00:31,  1.97s/it]\u001b[A\n",
      "loss 0.9679:  87%|████████▋ | 97/112 [03:24<00:29,  1.98s/it]\u001b[A\n",
      "loss 0.9320:  87%|████████▋ | 97/112 [03:26<00:29,  1.98s/it]\u001b[A\n",
      "loss 0.9320:  88%|████████▊ | 98/112 [03:26<00:27,  1.97s/it]\u001b[A\n",
      "loss 1.0590:  88%|████████▊ | 98/112 [03:28<00:27,  1.97s/it]\u001b[A\n",
      "loss 1.0590:  88%|████████▊ | 99/112 [03:28<00:25,  1.98s/it]\u001b[A\n",
      "loss 1.1542:  88%|████████▊ | 99/112 [03:30<00:25,  1.98s/it]\u001b[A\n",
      "loss 1.1542:  89%|████████▉ | 100/112 [03:30<00:23,  1.98s/it]\u001b[A\n",
      "loss 1.0602:  89%|████████▉ | 100/112 [03:31<00:23,  1.98s/it]\u001b[A\n",
      "loss 1.0602:  90%|█████████ | 101/112 [03:31<00:21,  1.97s/it]\u001b[A\n",
      "loss 0.9825:  90%|█████████ | 101/112 [03:33<00:21,  1.97s/it]\u001b[A\n",
      "loss 0.9825:  91%|█████████ | 102/112 [03:33<00:19,  1.97s/it]\u001b[A\n",
      "loss 1.0692:  91%|█████████ | 102/112 [03:35<00:19,  1.97s/it]\u001b[A\n",
      "loss 1.0692:  92%|█████████▏| 103/112 [03:35<00:17,  1.97s/it]\u001b[A\n",
      "loss 0.9849:  92%|█████████▏| 103/112 [03:37<00:17,  1.97s/it]\u001b[A\n",
      "loss 0.9849:  93%|█████████▎| 104/112 [03:37<00:15,  1.97s/it]\u001b[A\n",
      "loss 0.9785:  93%|█████████▎| 104/112 [03:39<00:15,  1.97s/it]\u001b[A\n",
      "loss 0.9785:  94%|█████████▍| 105/112 [03:39<00:13,  1.97s/it]\u001b[A\n",
      "loss 0.9070:  94%|█████████▍| 105/112 [03:41<00:13,  1.97s/it]\u001b[A\n",
      "loss 0.9070:  95%|█████████▍| 106/112 [03:41<00:11,  1.96s/it]\u001b[A\n",
      "loss 0.9712:  95%|█████████▍| 106/112 [03:43<00:11,  1.96s/it]\u001b[A\n",
      "loss 0.9712:  96%|█████████▌| 107/112 [03:43<00:09,  1.96s/it]\u001b[A\n",
      "loss 1.0037:  96%|█████████▌| 107/112 [03:45<00:09,  1.96s/it]\u001b[A\n",
      "loss 1.0037:  96%|█████████▋| 108/112 [03:45<00:07,  1.96s/it]\u001b[A\n",
      "loss 0.9288:  96%|█████████▋| 108/112 [03:47<00:07,  1.96s/it]\u001b[A\n",
      "loss 0.9288:  97%|█████████▋| 109/112 [03:47<00:05,  1.95s/it]\u001b[A\n",
      "loss 1.0889:  97%|█████████▋| 109/112 [03:49<00:05,  1.95s/it]\u001b[A\n",
      "loss 1.0889:  98%|█████████▊| 110/112 [03:49<00:03,  1.95s/it]\u001b[A\n",
      "loss 0.8854:  98%|█████████▊| 110/112 [03:51<00:03,  1.95s/it]\u001b[A\n",
      "loss 0.8854:  99%|█████████▉| 111/112 [03:51<00:01,  1.95s/it]\u001b[A\n",
      "loss 1.0577:  99%|█████████▉| 111/112 [03:52<00:01,  1.95s/it]\u001b[A\n",
      "loss 1.0577: 100%|██████████| 112/112 [03:52<00:00,  1.67s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [12:37<12:24, 248.03s/it]                \u001b[A\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3 - 0.9905592316389084\n",
      "saved checkpoint for epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loss 0.8961:   0%|          | 0/112 [00:01<?, ?it/s]\u001b[A\n",
      "loss 0.8961:   1%|          | 1/112 [00:01<03:37,  1.96s/it]\u001b[A\n",
      "loss 1.0130:   1%|          | 1/112 [00:03<03:37,  1.96s/it]\u001b[A\n",
      "loss 1.0130:   2%|▏         | 2/112 [00:03<03:35,  1.96s/it]\u001b[A\n",
      "loss 1.0422:   2%|▏         | 2/112 [00:05<03:35,  1.96s/it]\u001b[A\n",
      "loss 1.0422:   3%|▎         | 3/112 [00:05<03:32,  1.95s/it]\u001b[A\n",
      "loss 0.9525:   3%|▎         | 3/112 [00:07<03:32,  1.95s/it]\u001b[A\n",
      "loss 0.9525:   4%|▎         | 4/112 [00:07<03:30,  1.95s/it]\u001b[A\n",
      "loss 0.9408:   4%|▎         | 4/112 [00:09<03:30,  1.95s/it]\u001b[A\n",
      "loss 0.9408:   4%|▍         | 5/112 [00:09<03:28,  1.95s/it]\u001b[A\n",
      "loss 0.9883:   4%|▍         | 5/112 [00:11<03:28,  1.95s/it]\u001b[A\n",
      "loss 0.9883:   5%|▌         | 6/112 [00:11<03:26,  1.95s/it]\u001b[A\n",
      "loss 0.8973:   5%|▌         | 6/112 [00:13<03:26,  1.95s/it]\u001b[A\n",
      "loss 0.8973:   6%|▋         | 7/112 [00:13<03:24,  1.95s/it]\u001b[A\n",
      "loss 0.9757:   6%|▋         | 7/112 [00:15<03:24,  1.95s/it]\u001b[A\n",
      "loss 0.9757:   7%|▋         | 8/112 [00:15<03:23,  1.96s/it]\u001b[A\n",
      "loss 0.9953:   7%|▋         | 8/112 [00:17<03:23,  1.96s/it]\u001b[A\n",
      "loss 0.9953:   8%|▊         | 9/112 [00:17<03:20,  1.95s/it]\u001b[A\n",
      "loss 1.0785:   8%|▊         | 9/112 [00:19<03:20,  1.95s/it]\u001b[A\n",
      "loss 1.0785:   9%|▉         | 10/112 [00:19<03:19,  1.96s/it]\u001b[A\n",
      "loss 0.9889:   9%|▉         | 10/112 [00:21<03:19,  1.96s/it]\u001b[A\n",
      "loss 0.9889:  10%|▉         | 11/112 [00:21<03:20,  1.99s/it]\u001b[A\n",
      "loss 0.8724:  10%|▉         | 11/112 [00:23<03:20,  1.99s/it]\u001b[A\n",
      "loss 0.8724:  11%|█         | 12/112 [00:23<03:20,  2.00s/it]\u001b[A\n",
      "loss 1.1380:  11%|█         | 12/112 [00:25<03:20,  2.00s/it]\u001b[A\n",
      "loss 1.1380:  12%|█▏        | 13/112 [00:25<03:17,  2.00s/it]\u001b[A\n",
      "loss 0.9359:  12%|█▏        | 13/112 [00:28<03:17,  2.00s/it]\u001b[A\n",
      "loss 0.9359:  12%|█▎        | 14/112 [00:28<03:33,  2.17s/it]\u001b[A\n",
      "loss 1.0010:  12%|█▎        | 14/112 [00:30<03:33,  2.17s/it]\u001b[A\n",
      "loss 1.0010:  13%|█▎        | 15/112 [00:30<03:26,  2.13s/it]\u001b[A\n",
      "loss 1.0431:  13%|█▎        | 15/112 [00:32<03:26,  2.13s/it]\u001b[A\n",
      "loss 1.0431:  14%|█▍        | 16/112 [00:32<03:37,  2.27s/it]\u001b[A\n",
      "loss 1.0582:  14%|█▍        | 16/112 [00:35<03:37,  2.27s/it]\u001b[A\n",
      "loss 1.0582:  15%|█▌        | 17/112 [00:35<03:39,  2.31s/it]\u001b[A\n",
      "loss 0.8957:  15%|█▌        | 17/112 [00:37<03:39,  2.31s/it]\u001b[A\n",
      "loss 0.8957:  16%|█▌        | 18/112 [00:37<03:41,  2.36s/it]\u001b[A\n",
      "loss 0.9849:  16%|█▌        | 18/112 [00:39<03:41,  2.36s/it]\u001b[A\n",
      "loss 0.9849:  17%|█▋        | 19/112 [00:39<03:29,  2.25s/it]\u001b[A\n",
      "loss 1.0068:  17%|█▋        | 19/112 [00:41<03:29,  2.25s/it]\u001b[A\n",
      "loss 1.0068:  18%|█▊        | 20/112 [00:41<03:19,  2.17s/it]\u001b[A\n",
      "loss 1.0119:  18%|█▊        | 20/112 [00:43<03:19,  2.17s/it]\u001b[A\n",
      "loss 1.0119:  19%|█▉        | 21/112 [00:43<03:11,  2.10s/it]\u001b[A\n",
      "loss 0.9903:  19%|█▉        | 21/112 [00:45<03:11,  2.10s/it]\u001b[A\n",
      "loss 0.9903:  20%|█▉        | 22/112 [00:45<03:08,  2.10s/it]\u001b[A\n",
      "loss 0.9664:  20%|█▉        | 22/112 [00:47<03:08,  2.10s/it]\u001b[A\n",
      "loss 0.9664:  21%|██        | 23/112 [00:47<03:03,  2.06s/it]\u001b[A\n",
      "loss 1.0041:  21%|██        | 23/112 [00:49<03:03,  2.06s/it]\u001b[A\n",
      "loss 1.0041:  21%|██▏       | 24/112 [00:49<02:58,  2.03s/it]\u001b[A\n",
      "loss 1.0332:  21%|██▏       | 24/112 [00:51<02:58,  2.03s/it]\u001b[A\n",
      "loss 1.0332:  22%|██▏       | 25/112 [00:51<02:54,  2.01s/it]\u001b[A\n",
      "loss 0.9601:  22%|██▏       | 25/112 [00:53<02:54,  2.01s/it]\u001b[A\n",
      "loss 0.9601:  23%|██▎       | 26/112 [00:53<02:50,  1.98s/it]\u001b[A\n",
      "loss 0.9177:  23%|██▎       | 26/112 [00:55<02:50,  1.98s/it]\u001b[A\n",
      "loss 0.9177:  24%|██▍       | 27/112 [00:55<02:47,  1.97s/it]\u001b[A\n",
      "loss 1.0490:  24%|██▍       | 27/112 [00:57<02:47,  1.97s/it]\u001b[A\n",
      "loss 1.0490:  25%|██▌       | 28/112 [00:57<02:45,  1.97s/it]\u001b[A\n",
      "loss 0.8982:  25%|██▌       | 28/112 [00:59<02:45,  1.97s/it]\u001b[A\n",
      "loss 0.8982:  26%|██▌       | 29/112 [00:59<02:42,  1.96s/it]\u001b[A\n",
      "loss 1.0629:  26%|██▌       | 29/112 [01:01<02:42,  1.96s/it]\u001b[A\n",
      "loss 1.0629:  27%|██▋       | 30/112 [01:01<02:40,  1.96s/it]\u001b[A\n",
      "loss 1.1680:  27%|██▋       | 30/112 [01:03<02:40,  1.96s/it]\u001b[A\n",
      "loss 1.1680:  28%|██▊       | 31/112 [01:03<02:38,  1.96s/it]\u001b[A\n",
      "loss 0.8840:  28%|██▊       | 31/112 [01:05<02:38,  1.96s/it]\u001b[A\n",
      "loss 0.8840:  29%|██▊       | 32/112 [01:05<02:36,  1.96s/it]\u001b[A\n",
      "loss 1.0148:  29%|██▊       | 32/112 [01:07<02:36,  1.96s/it]\u001b[A\n",
      "loss 1.0148:  29%|██▉       | 33/112 [01:07<02:34,  1.96s/it]\u001b[A\n",
      "loss 0.9810:  29%|██▉       | 33/112 [01:09<02:34,  1.96s/it]\u001b[A\n",
      "loss 0.9810:  30%|███       | 34/112 [01:09<02:31,  1.95s/it]\u001b[A\n",
      "loss 0.9345:  30%|███       | 34/112 [01:11<02:31,  1.95s/it]\u001b[A\n",
      "loss 0.9345:  31%|███▏      | 35/112 [01:11<02:29,  1.95s/it]\u001b[A\n",
      "loss 1.0197:  31%|███▏      | 35/112 [01:13<02:29,  1.95s/it]\u001b[A\n",
      "loss 1.0197:  32%|███▏      | 36/112 [01:13<02:27,  1.95s/it]\u001b[A\n",
      "loss 0.9872:  32%|███▏      | 36/112 [01:15<02:27,  1.95s/it]\u001b[A\n",
      "loss 0.9872:  33%|███▎      | 37/112 [01:15<02:27,  1.97s/it]\u001b[A\n",
      "loss 0.9370:  33%|███▎      | 37/112 [01:16<02:27,  1.97s/it]\u001b[A\n",
      "loss 0.9370:  34%|███▍      | 38/112 [01:16<02:25,  1.96s/it]\u001b[A\n",
      "loss 0.9688:  34%|███▍      | 38/112 [01:18<02:25,  1.96s/it]\u001b[A\n",
      "loss 0.9688:  35%|███▍      | 39/112 [01:18<02:22,  1.95s/it]\u001b[A\n",
      "loss 0.9236:  35%|███▍      | 39/112 [01:20<02:22,  1.95s/it]\u001b[A\n",
      "loss 0.9236:  36%|███▌      | 40/112 [01:20<02:20,  1.95s/it]\u001b[A\n",
      "loss 0.9630:  36%|███▌      | 40/112 [01:22<02:20,  1.95s/it]\u001b[A\n",
      "loss 0.9630:  37%|███▋      | 41/112 [01:22<02:18,  1.94s/it]\u001b[A\n",
      "loss 0.9613:  37%|███▋      | 41/112 [01:24<02:18,  1.94s/it]\u001b[A\n",
      "loss 0.9613:  38%|███▊      | 42/112 [01:24<02:16,  1.95s/it]\u001b[A\n",
      "loss 0.9808:  38%|███▊      | 42/112 [01:26<02:16,  1.95s/it]\u001b[A\n",
      "loss 0.9808:  38%|███▊      | 43/112 [01:26<02:14,  1.95s/it]\u001b[A\n",
      "loss 1.0753:  38%|███▊      | 43/112 [01:28<02:14,  1.95s/it]\u001b[A\n",
      "loss 1.0753:  39%|███▉      | 44/112 [01:28<02:13,  1.96s/it]\u001b[A\n",
      "loss 1.0017:  39%|███▉      | 44/112 [01:31<02:13,  1.96s/it]\u001b[A\n",
      "loss 1.0017:  40%|████      | 45/112 [01:31<02:35,  2.32s/it]\u001b[A\n",
      "loss 1.0798:  40%|████      | 45/112 [01:34<02:35,  2.32s/it]\u001b[A\n",
      "loss 1.0798:  41%|████      | 46/112 [01:34<02:39,  2.41s/it]\u001b[A\n",
      "loss 0.8940:  41%|████      | 46/112 [01:36<02:39,  2.41s/it]\u001b[A\n",
      "loss 0.8940:  42%|████▏     | 47/112 [01:36<02:37,  2.43s/it]\u001b[A\n",
      "loss 0.9307:  42%|████▏     | 47/112 [01:39<02:37,  2.43s/it]\u001b[A\n",
      "loss 0.9307:  43%|████▎     | 48/112 [01:39<02:30,  2.35s/it]\u001b[A\n",
      "loss 1.0013:  43%|████▎     | 48/112 [01:41<02:30,  2.35s/it]\u001b[A\n",
      "loss 1.0013:  44%|████▍     | 49/112 [01:41<02:24,  2.30s/it]\u001b[A\n",
      "loss 0.9849:  44%|████▍     | 49/112 [01:43<02:24,  2.30s/it]\u001b[A\n",
      "loss 0.9849:  45%|████▍     | 50/112 [01:43<02:20,  2.26s/it]\u001b[A\n",
      "loss 0.8771:  45%|████▍     | 50/112 [01:45<02:20,  2.26s/it]\u001b[A\n",
      "loss 0.8771:  46%|████▌     | 51/112 [01:45<02:14,  2.21s/it]\u001b[A\n",
      "loss 1.0649:  46%|████▌     | 51/112 [01:47<02:14,  2.21s/it]\u001b[A\n",
      "loss 1.0649:  46%|████▋     | 52/112 [01:47<02:08,  2.15s/it]\u001b[A\n",
      "loss 0.9324:  46%|████▋     | 52/112 [01:49<02:08,  2.15s/it]\u001b[A\n",
      "loss 0.9324:  47%|████▋     | 53/112 [01:49<02:03,  2.10s/it]\u001b[A\n",
      "loss 0.9772:  47%|████▋     | 53/112 [01:51<02:03,  2.10s/it]\u001b[A\n",
      "loss 0.9772:  48%|████▊     | 54/112 [01:51<01:58,  2.05s/it]\u001b[A\n",
      "loss 1.0173:  48%|████▊     | 54/112 [01:53<01:58,  2.05s/it]\u001b[A\n",
      "loss 1.0173:  49%|████▉     | 55/112 [01:53<01:55,  2.03s/it]\u001b[A\n",
      "loss 1.0155:  49%|████▉     | 55/112 [01:55<01:55,  2.03s/it]\u001b[A\n",
      "loss 1.0155:  50%|█████     | 56/112 [01:55<01:52,  2.01s/it]\u001b[A\n",
      "loss 0.9635:  50%|█████     | 56/112 [01:57<01:52,  2.01s/it]\u001b[A\n",
      "loss 0.9635:  51%|█████     | 57/112 [01:57<01:49,  2.00s/it]\u001b[A\n",
      "loss 1.0124:  51%|█████     | 57/112 [01:59<01:49,  2.00s/it]\u001b[A\n",
      "loss 1.0124:  52%|█████▏    | 58/112 [01:59<01:47,  1.98s/it]\u001b[A\n",
      "loss 1.0184:  52%|█████▏    | 58/112 [02:01<01:47,  1.98s/it]\u001b[A\n",
      "loss 1.0184:  53%|█████▎    | 59/112 [02:01<01:48,  2.04s/it]\u001b[A\n",
      "loss 0.9453:  53%|█████▎    | 59/112 [02:03<01:48,  2.04s/it]\u001b[A\n",
      "loss 0.9453:  54%|█████▎    | 60/112 [02:03<01:49,  2.11s/it]\u001b[A\n",
      "loss 1.0775:  54%|█████▎    | 60/112 [02:05<01:49,  2.11s/it]\u001b[A\n",
      "loss 1.0775:  54%|█████▍    | 61/112 [02:05<01:46,  2.08s/it]\u001b[A\n",
      "loss 0.8772:  54%|█████▍    | 61/112 [02:08<01:46,  2.08s/it]\u001b[A\n",
      "loss 0.8772:  55%|█████▌    | 62/112 [02:08<01:46,  2.12s/it]\u001b[A\n",
      "loss 0.9324:  55%|█████▌    | 62/112 [02:10<01:46,  2.12s/it]\u001b[A\n",
      "loss 0.9324:  56%|█████▋    | 63/112 [02:10<01:44,  2.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.9765:  56%|█████▋    | 63/112 [02:12<01:44,  2.14s/it]\u001b[A\n",
      "loss 0.9765:  57%|█████▋    | 64/112 [02:12<01:44,  2.17s/it]\u001b[A\n",
      "loss 1.0609:  57%|█████▋    | 64/112 [02:14<01:44,  2.17s/it]\u001b[A\n",
      "loss 1.0609:  58%|█████▊    | 65/112 [02:14<01:39,  2.12s/it]\u001b[A\n",
      "loss 0.9248:  58%|█████▊    | 65/112 [02:16<01:39,  2.12s/it]\u001b[A\n",
      "loss 0.9248:  59%|█████▉    | 66/112 [02:16<01:35,  2.07s/it]\u001b[A\n",
      "loss 0.9433:  59%|█████▉    | 66/112 [02:18<01:35,  2.07s/it]\u001b[A\n",
      "loss 0.9433:  60%|█████▉    | 67/112 [02:18<01:31,  2.03s/it]\u001b[A\n",
      "loss 0.9801:  60%|█████▉    | 67/112 [02:20<01:31,  2.03s/it]\u001b[A\n",
      "loss 0.9801:  61%|██████    | 68/112 [02:20<01:31,  2.09s/it]\u001b[A\n",
      "loss 0.8727:  61%|██████    | 68/112 [02:22<01:31,  2.09s/it]\u001b[A\n",
      "loss 0.8727:  62%|██████▏   | 69/112 [02:22<01:30,  2.10s/it]\u001b[A\n",
      "loss 1.0034:  62%|██████▏   | 69/112 [02:24<01:30,  2.10s/it]\u001b[A\n",
      "loss 1.0034:  62%|██████▎   | 70/112 [02:24<01:30,  2.15s/it]\u001b[A\n",
      "loss 0.9423:  62%|██████▎   | 70/112 [02:26<01:30,  2.15s/it]\u001b[A\n",
      "loss 0.9423:  63%|██████▎   | 71/112 [02:26<01:25,  2.09s/it]\u001b[A\n",
      "loss 0.9541:  63%|██████▎   | 71/112 [02:28<01:25,  2.09s/it]\u001b[A\n",
      "loss 0.9541:  64%|██████▍   | 72/112 [02:28<01:22,  2.07s/it]\u001b[A\n",
      "loss 0.9869:  64%|██████▍   | 72/112 [02:30<01:22,  2.07s/it]\u001b[A\n",
      "loss 0.9869:  65%|██████▌   | 73/112 [02:30<01:19,  2.03s/it]\u001b[A\n",
      "loss 1.0052:  65%|██████▌   | 73/112 [02:32<01:19,  2.03s/it]\u001b[A\n",
      "loss 1.0052:  66%|██████▌   | 74/112 [02:32<01:15,  2.00s/it]\u001b[A\n",
      "loss 1.0056:  66%|██████▌   | 74/112 [02:34<01:15,  2.00s/it]\u001b[A\n",
      "loss 1.0056:  67%|██████▋   | 75/112 [02:34<01:13,  1.98s/it]\u001b[A\n",
      "loss 0.9702:  67%|██████▋   | 75/112 [02:36<01:13,  1.98s/it]\u001b[A\n",
      "loss 0.9702:  68%|██████▊   | 76/112 [02:36<01:11,  1.98s/it]\u001b[A\n",
      "loss 0.9665:  68%|██████▊   | 76/112 [02:38<01:11,  1.98s/it]\u001b[A\n",
      "loss 0.9665:  69%|██████▉   | 77/112 [02:38<01:09,  1.98s/it]\u001b[A\n",
      "loss 1.0641:  69%|██████▉   | 77/112 [02:40<01:09,  1.98s/it]\u001b[A\n",
      "loss 1.0641:  70%|██████▉   | 78/112 [02:40<01:07,  1.98s/it]\u001b[A\n",
      "loss 0.9626:  70%|██████▉   | 78/112 [02:42<01:07,  1.98s/it]\u001b[A\n",
      "loss 0.9626:  71%|███████   | 79/112 [02:42<01:05,  1.97s/it]\u001b[A\n",
      "loss 0.9623:  71%|███████   | 79/112 [02:44<01:05,  1.97s/it]\u001b[A\n",
      "loss 0.9623:  71%|███████▏  | 80/112 [02:44<01:02,  1.96s/it]\u001b[A\n",
      "loss 1.0220:  71%|███████▏  | 80/112 [02:46<01:02,  1.96s/it]\u001b[A\n",
      "loss 1.0220:  72%|███████▏  | 81/112 [02:46<01:00,  1.97s/it]\u001b[A\n",
      "loss 0.9125:  72%|███████▏  | 81/112 [02:48<01:00,  1.97s/it]\u001b[A\n",
      "loss 0.9125:  73%|███████▎  | 82/112 [02:48<01:00,  2.00s/it]\u001b[A\n",
      "loss 0.9517:  73%|███████▎  | 82/112 [02:50<01:00,  2.00s/it]\u001b[A\n",
      "loss 0.9517:  74%|███████▍  | 83/112 [02:50<00:57,  2.00s/it]\u001b[A\n",
      "loss 0.9536:  74%|███████▍  | 83/112 [02:52<00:57,  2.00s/it]\u001b[A\n",
      "loss 0.9536:  75%|███████▌  | 84/112 [02:52<00:55,  1.98s/it]\u001b[A\n",
      "loss 0.8806:  75%|███████▌  | 84/112 [02:54<00:55,  1.98s/it]\u001b[A\n",
      "loss 0.8806:  76%|███████▌  | 85/112 [02:54<00:53,  1.97s/it]\u001b[A\n",
      "loss 0.9039:  76%|███████▌  | 85/112 [02:56<00:53,  1.97s/it]\u001b[A\n",
      "loss 0.9039:  77%|███████▋  | 86/112 [02:56<00:51,  1.97s/it]\u001b[A\n",
      "loss 0.9170:  77%|███████▋  | 86/112 [02:58<00:51,  1.97s/it]\u001b[A\n",
      "loss 0.9170:  78%|███████▊  | 87/112 [02:58<00:48,  1.96s/it]\u001b[A\n",
      "loss 0.9329:  78%|███████▊  | 87/112 [03:00<00:48,  1.96s/it]\u001b[A\n",
      "loss 0.9329:  79%|███████▊  | 88/112 [03:00<00:46,  1.95s/it]\u001b[A\n",
      "loss 1.0043:  79%|███████▊  | 88/112 [03:02<00:46,  1.95s/it]\u001b[A\n",
      "loss 1.0043:  79%|███████▉  | 89/112 [03:02<00:44,  1.94s/it]\u001b[A\n",
      "loss 1.0730:  79%|███████▉  | 89/112 [03:04<00:44,  1.94s/it]\u001b[A\n",
      "loss 1.0730:  80%|████████  | 90/112 [03:04<00:45,  2.06s/it]\u001b[A\n",
      "loss 1.0488:  80%|████████  | 90/112 [03:06<00:45,  2.06s/it]\u001b[A\n",
      "loss 1.0488:  81%|████████▏ | 91/112 [03:06<00:44,  2.14s/it]\u001b[A\n",
      "loss 1.0533:  81%|████████▏ | 91/112 [03:09<00:44,  2.14s/it]\u001b[A\n",
      "loss 1.0533:  82%|████████▏ | 92/112 [03:09<00:43,  2.16s/it]\u001b[A\n",
      "loss 1.0082:  82%|████████▏ | 92/112 [03:11<00:43,  2.16s/it]\u001b[A\n",
      "loss 1.0082:  83%|████████▎ | 93/112 [03:11<00:41,  2.17s/it]\u001b[A\n",
      "loss 0.9562:  83%|████████▎ | 93/112 [03:13<00:41,  2.17s/it]\u001b[A\n",
      "loss 0.9562:  84%|████████▍ | 94/112 [03:13<00:39,  2.19s/it]\u001b[A\n",
      "loss 0.9468:  84%|████████▍ | 94/112 [03:16<00:39,  2.19s/it]\u001b[A\n",
      "loss 0.9468:  85%|████████▍ | 95/112 [03:16<00:40,  2.40s/it]\u001b[A\n",
      "loss 1.0303:  85%|████████▍ | 95/112 [03:18<00:40,  2.40s/it]\u001b[A\n",
      "loss 1.0303:  86%|████████▌ | 96/112 [03:18<00:37,  2.36s/it]\u001b[A\n",
      "loss 1.0663:  86%|████████▌ | 96/112 [03:20<00:37,  2.36s/it]\u001b[A\n",
      "loss 1.0663:  87%|████████▋ | 97/112 [03:20<00:33,  2.25s/it]\u001b[A\n",
      "loss 0.8786:  87%|████████▋ | 97/112 [03:23<00:33,  2.25s/it]\u001b[A\n",
      "loss 0.8786:  88%|████████▊ | 98/112 [03:23<00:32,  2.29s/it]\u001b[A\n",
      "loss 1.2781:  88%|████████▊ | 98/112 [03:25<00:32,  2.29s/it]\u001b[A\n",
      "loss 1.2781:  88%|████████▊ | 99/112 [03:25<00:31,  2.41s/it]\u001b[A\n",
      "loss 0.9006:  88%|████████▊ | 99/112 [03:28<00:31,  2.41s/it]\u001b[A\n",
      "loss 0.9006:  89%|████████▉ | 100/112 [03:28<00:31,  2.63s/it]\u001b[A\n",
      "loss 0.9403:  89%|████████▉ | 100/112 [03:30<00:31,  2.63s/it]\u001b[A\n",
      "loss 0.9403:  90%|█████████ | 101/112 [03:30<00:26,  2.43s/it]\u001b[A\n",
      "loss 1.0890:  90%|█████████ | 101/112 [03:32<00:26,  2.43s/it]\u001b[A\n",
      "loss 1.0890:  91%|█████████ | 102/112 [03:32<00:22,  2.29s/it]\u001b[A\n",
      "loss 1.0070:  91%|█████████ | 102/112 [03:34<00:22,  2.29s/it]\u001b[A\n",
      "loss 1.0070:  92%|█████████▏| 103/112 [03:34<00:19,  2.20s/it]\u001b[A\n",
      "loss 1.0477:  92%|█████████▏| 103/112 [03:36<00:19,  2.20s/it]\u001b[A\n",
      "loss 1.0477:  93%|█████████▎| 104/112 [03:36<00:17,  2.13s/it]\u001b[A\n",
      "loss 0.9309:  93%|█████████▎| 104/112 [03:38<00:17,  2.13s/it]\u001b[A\n",
      "loss 0.9309:  94%|█████████▍| 105/112 [03:38<00:14,  2.09s/it]\u001b[A\n",
      "loss 0.9689:  94%|█████████▍| 105/112 [03:40<00:14,  2.09s/it]\u001b[A\n",
      "loss 0.9689:  95%|█████████▍| 106/112 [03:40<00:12,  2.05s/it]\u001b[A\n",
      "loss 0.8815:  95%|█████████▍| 106/112 [03:42<00:12,  2.05s/it]\u001b[A\n",
      "loss 0.8815:  96%|█████████▌| 107/112 [03:42<00:10,  2.03s/it]\u001b[A\n",
      "loss 0.9611:  96%|█████████▌| 107/112 [03:44<00:10,  2.03s/it]\u001b[A\n",
      "loss 0.9611:  96%|█████████▋| 108/112 [03:44<00:08,  2.01s/it]\u001b[A\n",
      "loss 0.9900:  96%|█████████▋| 108/112 [03:46<00:08,  2.01s/it]\u001b[A\n",
      "loss 0.9900:  97%|█████████▋| 109/112 [03:46<00:05,  2.00s/it]\u001b[A\n",
      "loss 0.9766:  97%|█████████▋| 109/112 [03:48<00:05,  2.00s/it]\u001b[A\n",
      "loss 0.9766:  98%|█████████▊| 110/112 [03:48<00:03,  1.98s/it]\u001b[A\n",
      "loss 0.9924:  98%|█████████▊| 110/112 [03:50<00:03,  1.98s/it]\u001b[A\n",
      "loss 0.9924:  99%|█████████▉| 111/112 [03:50<00:01,  1.97s/it]\u001b[A\n",
      "loss 1.1212:  99%|█████████▉| 111/112 [03:51<00:01,  1.97s/it]\u001b[A\n",
      "loss 1.1212: 100%|██████████| 112/112 [03:51<00:00,  1.68s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [16:29<08:03, 241.56s/it]                \u001b[A\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4 - 0.9830136716365814\n",
      "saved checkpoint for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loss 1.0064:   0%|          | 0/112 [00:01<?, ?it/s]\u001b[A\n",
      "loss 1.0064:   1%|          | 1/112 [00:01<03:36,  1.95s/it]\u001b[A\n",
      "loss 1.0835:   1%|          | 1/112 [00:03<03:36,  1.95s/it]\u001b[A\n",
      "loss 1.0835:   2%|▏         | 2/112 [00:03<03:34,  1.95s/it]\u001b[A\n",
      "loss 0.8808:   2%|▏         | 2/112 [00:05<03:34,  1.95s/it]\u001b[A\n",
      "loss 0.8808:   3%|▎         | 3/112 [00:05<03:33,  1.95s/it]\u001b[A\n",
      "loss 1.0567:   3%|▎         | 3/112 [00:07<03:33,  1.95s/it]\u001b[A\n",
      "loss 1.0567:   4%|▎         | 4/112 [00:07<03:30,  1.95s/it]\u001b[A\n",
      "loss 1.0392:   4%|▎         | 4/112 [00:09<03:30,  1.95s/it]\u001b[A\n",
      "loss 1.0392:   4%|▍         | 5/112 [00:09<03:28,  1.95s/it]\u001b[A\n",
      "loss 0.8578:   4%|▍         | 5/112 [00:11<03:28,  1.95s/it]\u001b[A\n",
      "loss 0.8578:   5%|▌         | 6/112 [00:11<03:26,  1.94s/it]\u001b[A\n",
      "loss 0.9339:   5%|▌         | 6/112 [00:13<03:26,  1.94s/it]\u001b[A\n",
      "loss 0.9339:   6%|▋         | 7/112 [00:13<03:23,  1.94s/it]\u001b[A\n",
      "loss 1.0083:   6%|▋         | 7/112 [00:15<03:23,  1.94s/it]\u001b[A\n",
      "loss 1.0083:   7%|▋         | 8/112 [00:15<03:22,  1.95s/it]\u001b[A\n",
      "loss 0.9703:   7%|▋         | 8/112 [00:17<03:22,  1.95s/it]\u001b[A\n",
      "loss 0.9703:   8%|▊         | 9/112 [00:17<03:20,  1.95s/it]\u001b[A\n",
      "loss 0.9936:   8%|▊         | 9/112 [00:19<03:20,  1.95s/it]\u001b[A\n",
      "loss 0.9936:   9%|▉         | 10/112 [00:19<03:23,  2.00s/it]\u001b[A\n",
      "loss 0.9569:   9%|▉         | 10/112 [00:22<03:23,  2.00s/it]\u001b[A\n",
      "loss 0.9569:  10%|▉         | 11/112 [00:22<03:37,  2.15s/it]\u001b[A\n",
      "loss 1.1281:  10%|▉         | 11/112 [00:24<03:37,  2.15s/it]\u001b[A\n",
      "loss 1.1281:  11%|█         | 12/112 [00:24<03:29,  2.10s/it]\u001b[A\n",
      "loss 1.0012:  11%|█         | 12/112 [00:26<03:29,  2.10s/it]\u001b[A\n",
      "loss 1.0012:  12%|█▏        | 13/112 [00:26<03:23,  2.05s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "vd = valid_dataloader if mode == 'valid' else None\n",
    "trainer.train(6, train_dataloader, vd, resume_only_model=True, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._load_checkpoint(only_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'valid':\n",
    "    valid_predictions = trainer.predict(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trainer.predict(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sequence_data.index = range(len(valid_sequence_data))\n",
    "test_sequence_data.index = range(len(test_sequence_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'valid':\n",
    "    valid_sequence_data['predictions'] = pd.Series(valid_predictions.tolist())\n",
    "test_sequence_data['predictions'] = pd.Series(test_predictions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'valid':\n",
    "    valid_sequence_data['X'] = valid_sequence_data['x_sequence'].apply(lambda x: x[:, 0])\n",
    "    valid_sequence_data['Y'] = valid_sequence_data['y_sequence'].apply(lambda x: x[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_data(scale_map, data_df, columns=['predictions', 'y_sequence', 'x_sequence']):\n",
    "    rescaled_data = pd.DataFrame()\n",
    "    for store_item_id, item_data in tqdm(data_df.groupby('store_item_id', as_index=False)):\n",
    "        mu = scale_map[store_item_id]['mu']\n",
    "        sigma = scale_map[store_item_id]['sigma']\n",
    "        for col in columns:\n",
    "            item_data[col] = item_data[col].apply(lambda x: (np.array(x) * sigma) + mu)\n",
    "        rescaled_data = pd.concat([rescaled_data, item_data], ignore_index=True)\n",
    "    return rescaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'valid':\n",
    "    valid_rescaled = rescale_data(scale_map, valid_sequence_data, columns=['X', 'Y', 'predictions'])\n",
    "test_rescaled = rescale_data(scale_map, test_sequence_data, columns=['predictions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'valid':\n",
    "    valid_sequence_data = valid_rescaled\n",
    "test_sequence_data = test_rescaled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8(takehometest)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
